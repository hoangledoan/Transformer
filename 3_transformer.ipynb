{"cells":[{"cell_type":"code","execution_count":66,"id":"635e404efc259d7e","metadata":{"executionInfo":{"elapsed":280,"status":"ok","timestamp":1720358413154,"user":{"displayName":"Hoàng Lê","userId":"12538776912584899644"},"user_tz":-120},"id":"635e404efc259d7e"},"outputs":[],"source":["from exercise_code.trainer import Trainer\n","from exercise_code.network import SmoothCrossEntropyLoss\n","from transformers import PreTrainedTokenizerFast\n","from transformers import TFAutoModel\n","from tokenizers import Tokenizer\n","\n","tokenizer = None\n","\n","\n","tokenizer = load_pretrained_fast()\n","# tokenizer = PreTrainedTokenizerFast.from_pretrained('distilbert-base-uncased')\n","# if tokenizer.pad_token is None:\n","#     tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n","\n","hparams = {\n","    'd_model': 128,\n","    'd_k': 32,\n","    'd_v': 32,\n","    'n_heads': 4,\n","    'd_ff': 256,\n","    'n': 3,\n","    'dropout': 0.1\n","}\n","\n","\n","model = Transformer(vocab_size=len(tokenizer),\n","                    eos_token_id=tokenizer.eos_token_id,\n","                    hparams=hparams)"]},{"cell_type":"code","execution_count":73,"id":"b878608289c10f90","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":260,"status":"ok","timestamp":1720358496765,"user":{"displayName":"Hoàng Lê","userId":"12538776912584899644"},"user_tz":-120},"id":"b878608289c10f90","outputId":"79354fd8-917f-4d65-e0fb-f330eb36ad75"},"outputs":[{"name":"stdout","output_type":"stream","text":["16\n"]}],"source":["optimizer = None\n","scheduler = None\n","\n","epochs = 1000\n","batch_size = 16\n","import torch.optim as optim\n","\n","lr_start =1e-4\n","\n","\n","optimizer = Adam(model.parameters(), lr=lr_start)\n","\n","\n","loss_func = SmoothCrossEntropyLoss(smoothing=0.1)\n","file_path = os.path.join(dataset_path, 'dummyDatasets', 'ds_dummy')\n","collator = CustomCollator(tokenizer=tokenizer)\n","dataset = CustomIterableDataset(file_path)\n","dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=collator)\n","\n","# For Apple M1/M2/M3 users: Try out the MPS framework, it will significantly speed up your training!\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","elif MPS_AVAILABLE:\n","    if torch.backends.mps.is_available():\n","        device = torch.device(\"mps\")\n","    else:\n","        device = torch.device(\"cpu\")\n","else:\n","    device = torch.device(\"cpu\")\n","\n","trainer = Trainer(model=model,\n","                  loss_func=loss_func,\n","                  train_loader=dataloader,\n","                  val_loader=None,\n","                  optimizer=optimizer,\n","                  scheduler=scheduler,\n","                  epochs=epochs,\n","                  device=device,\n","                  optimizer_interval=0, \n","                  checkpoint_interval=0) "]},{"cell_type":"code","execution_count":74,"id":"974182aeee4cda2a","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":133361,"status":"error","timestamp":1720358631201,"user":{"displayName":"Hoàng Lê","userId":"12538776912584899644"},"user_tz":-120},"id":"974182aeee4cda2a","outputId":"10a611d4-4739-419b-c648-6b2169aeb451"},"outputs":[{"name":"stderr","output_type":"stream","text":["Training Epoch 1/1000: 100%|██████████| 4/4 [00:00<00:00, 29.02 batches/s, loss=3.372/13.288, train accuracy=78.571/3.796, learning_rate=1.000e-04]\n","Training Epoch 2/1000: 100%|██████████| 4/4 [00:00<00:00, 32.05 batches/s, loss=3.653/13.268, train accuracy=64.286/4.279, learning_rate=1.000e-04]\n","Training Epoch 3/1000: 100%|██████████| 4/4 [00:00<00:00, 28.90 batches/s, loss=3.310/13.174, train accuracy=92.857/4.555, learning_rate=1.000e-04]\n","Training Epoch 4/1000: 100%|██████████| 4/4 [00:00<00:00, 24.68 batches/s, loss=3.728/13.112, train accuracy=78.571/4.900, learning_rate=1.000e-04]\n","Training Epoch 5/1000: 100%|██████████| 4/4 [00:00<00:00, 27.88 batches/s, loss=3.423/12.999, train accuracy=85.714/4.900, learning_rate=1.000e-04]\n","Training Epoch 6/1000: 100%|██████████| 4/4 [00:00<00:00, 27.82 batches/s, loss=3.369/12.909, train accuracy=78.571/4.003, learning_rate=1.000e-04]\n","Training Epoch 7/1000: 100%|██████████| 4/4 [00:00<00:00, 31.63 batches/s, loss=3.259/12.887, train accuracy=85.714/4.141, learning_rate=1.000e-04]\n","Training Epoch 8/1000: 100%|██████████| 4/4 [00:00<00:00, 31.55 batches/s, loss=3.396/12.781, train accuracy=78.571/4.210, learning_rate=1.000e-04]\n","Training Epoch 9/1000: 100%|██████████| 4/4 [00:00<00:00, 30.99 batches/s, loss=3.212/12.671, train accuracy=92.857/4.555, learning_rate=1.000e-04]\n","Training Epoch 10/1000: 100%|██████████| 4/4 [00:00<00:00, 27.82 batches/s, loss=3.158/12.583, train accuracy=92.857/4.693, learning_rate=1.000e-04]\n","Training Epoch 11/1000: 100%|██████████| 4/4 [00:00<00:00, 22.66 batches/s, loss=3.031/12.508, train accuracy=100.000/4.900, learning_rate=1.000e-04]\n","Training Epoch 12/1000: 100%|██████████| 4/4 [00:00<00:00, 26.10 batches/s, loss=3.288/12.561, train accuracy=78.571/4.417, learning_rate=1.000e-04]\n","Training Epoch 13/1000: 100%|██████████| 4/4 [00:00<00:00, 30.12 batches/s, loss=3.184/12.411, train accuracy=78.571/5.314, learning_rate=1.000e-04]\n","Training Epoch 14/1000: 100%|██████████| 4/4 [00:00<00:00, 31.25 batches/s, loss=3.137/12.431, train accuracy=92.857/4.693, learning_rate=1.000e-04]\n","Training Epoch 15/1000: 100%|██████████| 4/4 [00:00<00:00, 31.58 batches/s, loss=3.289/12.355, train accuracy=85.714/4.831, learning_rate=1.000e-04]\n","Training Epoch 16/1000: 100%|██████████| 4/4 [00:00<00:00, 29.62 batches/s, loss=3.252/12.306, train accuracy=78.571/4.900, learning_rate=1.000e-04]\n","Training Epoch 17/1000: 100%|██████████| 4/4 [00:00<00:00, 19.65 batches/s, loss=3.351/12.252, train accuracy=71.429/4.762, learning_rate=1.000e-04]\n","Training Epoch 18/1000: 100%|██████████| 4/4 [00:00<00:00, 19.93 batches/s, loss=3.719/12.341, train accuracy=50.000/5.038, learning_rate=1.000e-04]\n","Training Epoch 19/1000: 100%|██████████| 4/4 [00:00<00:00, 19.79 batches/s, loss=3.068/12.105, train accuracy=92.857/5.314, learning_rate=1.000e-04]\n","Training Epoch 20/1000: 100%|██████████| 4/4 [00:00<00:00, 22.00 batches/s, loss=2.985/11.965, train accuracy=100.000/5.038, learning_rate=1.000e-04]\n","Training Epoch 21/1000: 100%|██████████| 4/4 [00:00<00:00, 21.71 batches/s, loss=2.891/11.975, train accuracy=100.000/5.383, learning_rate=1.000e-04]\n","Training Epoch 22/1000: 100%|██████████| 4/4 [00:00<00:00, 17.37 batches/s, loss=2.911/11.873, train accuracy=92.857/5.590, learning_rate=1.000e-04]\n","Training Epoch 23/1000: 100%|██████████| 4/4 [00:00<00:00, 22.11 batches/s, loss=2.948/11.932, train accuracy=92.857/4.900, learning_rate=1.000e-04]\n","Training Epoch 24/1000: 100%|██████████| 4/4 [00:00<00:00, 14.42 batches/s, loss=3.190/11.904, train accuracy=85.714/5.107, learning_rate=1.000e-04]\n","Training Epoch 25/1000: 100%|██████████| 4/4 [00:00<00:00,  5.68 batches/s, loss=3.144/11.795, train accuracy=92.857/5.659, learning_rate=1.000e-04]\n","Training Epoch 26/1000: 100%|██████████| 4/4 [00:00<00:00, 13.89 batches/s, loss=2.921/11.732, train accuracy=100.000/5.866, learning_rate=1.000e-04]\n","Training Epoch 27/1000: 100%|██████████| 4/4 [00:00<00:00, 21.12 batches/s, loss=2.867/11.685, train accuracy=92.857/4.900, learning_rate=1.000e-04]\n","Training Epoch 28/1000: 100%|██████████| 4/4 [00:00<00:00, 17.92 batches/s, loss=2.850/11.582, train accuracy=100.000/5.521, learning_rate=1.000e-04]\n","Training Epoch 29/1000: 100%|██████████| 4/4 [00:00<00:00, 18.44 batches/s, loss=2.912/11.535, train accuracy=100.000/5.383, learning_rate=1.000e-04]\n","Training Epoch 30/1000: 100%|██████████| 4/4 [00:00<00:00, 20.17 batches/s, loss=2.990/11.551, train accuracy=92.857/5.728, learning_rate=1.000e-04]\n","Training Epoch 31/1000: 100%|██████████| 4/4 [00:00<00:00, 18.67 batches/s, loss=3.011/11.490, train accuracy=92.857/5.383, learning_rate=1.000e-04]\n","Training Epoch 32/1000: 100%|██████████| 4/4 [00:00<00:00, 23.47 batches/s, loss=3.028/11.393, train accuracy=92.857/5.935, learning_rate=1.000e-04]\n","Training Epoch 33/1000: 100%|██████████| 4/4 [00:00<00:00, 25.52 batches/s, loss=2.925/11.376, train accuracy=92.857/6.418, learning_rate=1.000e-04]\n","Training Epoch 34/1000: 100%|██████████| 4/4 [00:00<00:00, 27.61 batches/s, loss=2.820/11.212, train accuracy=100.000/6.901, learning_rate=1.000e-04]\n","Training Epoch 35/1000: 100%|██████████| 4/4 [00:00<00:00, 31.00 batches/s, loss=2.793/11.233, train accuracy=100.000/6.418, learning_rate=1.000e-04]\n","Training Epoch 36/1000: 100%|██████████| 4/4 [00:00<00:00, 30.16 batches/s, loss=2.945/11.237, train accuracy=85.714/6.004, learning_rate=1.000e-04]\n","Training Epoch 37/1000: 100%|██████████| 4/4 [00:00<00:00, 31.23 batches/s, loss=2.785/11.109, train accuracy=100.000/6.211, learning_rate=1.000e-04]\n","Training Epoch 38/1000: 100%|██████████| 4/4 [00:00<00:00, 30.87 batches/s, loss=2.903/11.110, train accuracy=100.000/5.659, learning_rate=1.000e-04]\n","Training Epoch 39/1000: 100%|██████████| 4/4 [00:00<00:00, 32.16 batches/s, loss=2.924/11.050, train accuracy=92.857/5.866, learning_rate=1.000e-04]\n","Training Epoch 40/1000: 100%|██████████| 4/4 [00:00<00:00, 25.40 batches/s, loss=3.059/11.040, train accuracy=85.714/6.280, learning_rate=1.000e-04]\n","Training Epoch 41/1000: 100%|██████████| 4/4 [00:00<00:00, 24.35 batches/s, loss=2.836/10.980, train accuracy=92.857/6.142, learning_rate=1.000e-04]\n","Training Epoch 42/1000: 100%|██████████| 4/4 [00:00<00:00, 30.82 batches/s, loss=2.850/10.904, train accuracy=92.857/6.556, learning_rate=1.000e-04]\n","Training Epoch 43/1000: 100%|██████████| 4/4 [00:00<00:00, 31.57 batches/s, loss=2.759/10.846, train accuracy=100.000/6.142, learning_rate=1.000e-04]\n","Training Epoch 44/1000: 100%|██████████| 4/4 [00:00<00:00, 31.06 batches/s, loss=2.792/10.781, train accuracy=92.857/7.039, learning_rate=1.000e-04]\n","Training Epoch 45/1000: 100%|██████████| 4/4 [00:00<00:00, 31.87 batches/s, loss=2.773/10.775, train accuracy=100.000/6.556, learning_rate=1.000e-04]\n","Training Epoch 46/1000: 100%|██████████| 4/4 [00:00<00:00, 30.99 batches/s, loss=2.795/10.760, train accuracy=100.000/6.901, learning_rate=1.000e-04]\n","Training Epoch 47/1000: 100%|██████████| 4/4 [00:00<00:00, 25.40 batches/s, loss=2.856/10.688, train accuracy=92.857/6.625, learning_rate=1.000e-04]\n","Training Epoch 48/1000: 100%|██████████| 4/4 [00:00<00:00, 26.83 batches/s, loss=2.698/10.607, train accuracy=100.000/6.832, learning_rate=1.000e-04]\n","Training Epoch 49/1000: 100%|██████████| 4/4 [00:00<00:00, 28.12 batches/s, loss=2.699/10.609, train accuracy=92.857/6.832, learning_rate=1.000e-04]\n","Training Epoch 50/1000: 100%|██████████| 4/4 [00:00<00:00, 30.36 batches/s, loss=2.873/10.586, train accuracy=85.714/6.211, learning_rate=1.000e-04]\n","Training Epoch 51/1000: 100%|██████████| 4/4 [00:00<00:00, 31.64 batches/s, loss=2.792/10.497, train accuracy=100.000/7.108, learning_rate=1.000e-04]\n","Training Epoch 52/1000: 100%|██████████| 4/4 [00:00<00:00, 30.49 batches/s, loss=2.723/10.460, train accuracy=100.000/6.832, learning_rate=1.000e-04]\n","Training Epoch 53/1000: 100%|██████████| 4/4 [00:00<00:00, 31.79 batches/s, loss=2.765/10.399, train accuracy=92.857/6.280, learning_rate=1.000e-04]\n","Training Epoch 54/1000: 100%|██████████| 4/4 [00:00<00:00, 24.47 batches/s, loss=2.862/10.358, train accuracy=92.857/6.280, learning_rate=1.000e-04]\n","Training Epoch 55/1000: 100%|██████████| 4/4 [00:00<00:00, 27.69 batches/s, loss=2.655/10.249, train accuracy=100.000/6.556, learning_rate=1.000e-04]\n","Training Epoch 56/1000: 100%|██████████| 4/4 [00:00<00:00, 27.50 batches/s, loss=2.635/10.343, train accuracy=100.000/6.970, learning_rate=1.000e-04]\n","Training Epoch 57/1000: 100%|██████████| 4/4 [00:00<00:00, 29.67 batches/s, loss=2.723/10.255, train accuracy=92.857/6.349, learning_rate=1.000e-04]\n","Training Epoch 58/1000: 100%|██████████| 4/4 [00:00<00:00, 31.63 batches/s, loss=2.624/10.127, train accuracy=100.000/8.627, learning_rate=1.000e-04]\n","Training Epoch 59/1000: 100%|██████████| 4/4 [00:00<00:00, 32.23 batches/s, loss=2.622/10.160, train accuracy=100.000/7.591, learning_rate=1.000e-04]\n","Training Epoch 60/1000: 100%|██████████| 4/4 [00:00<00:00, 30.23 batches/s, loss=2.679/10.115, train accuracy=100.000/7.177, learning_rate=1.000e-04]\n","Training Epoch 61/1000: 100%|██████████| 4/4 [00:00<00:00, 23.09 batches/s, loss=2.615/10.081, train accuracy=100.000/7.108, learning_rate=1.000e-04]\n","Training Epoch 62/1000: 100%|██████████| 4/4 [00:00<00:00, 30.11 batches/s, loss=2.585/9.996, train accuracy=100.000/6.625, learning_rate=1.000e-04]\n","Training Epoch 63/1000: 100%|██████████| 4/4 [00:00<00:00, 28.06 batches/s, loss=2.633/9.987, train accuracy=100.000/7.384, learning_rate=1.000e-04]\n","Training Epoch 64/1000: 100%|██████████| 4/4 [00:00<00:00, 32.39 batches/s, loss=2.610/9.886, train accuracy=100.000/7.522, learning_rate=1.000e-04]\n","Training Epoch 65/1000: 100%|██████████| 4/4 [00:00<00:00, 31.37 batches/s, loss=2.552/9.829, train accuracy=100.000/7.315, learning_rate=1.000e-04]\n","Training Epoch 66/1000: 100%|██████████| 4/4 [00:00<00:00, 31.33 batches/s, loss=2.618/9.752, train accuracy=100.000/7.867, learning_rate=1.000e-04]\n","Training Epoch 67/1000: 100%|██████████| 4/4 [00:00<00:00, 28.64 batches/s, loss=2.591/9.807, train accuracy=100.000/7.246, learning_rate=1.000e-04]\n","Training Epoch 68/1000: 100%|██████████| 4/4 [00:00<00:00, 23.09 batches/s, loss=2.572/9.705, train accuracy=100.000/7.246, learning_rate=1.000e-04]\n","Training Epoch 69/1000: 100%|██████████| 4/4 [00:00<00:00, 29.73 batches/s, loss=2.554/9.709, train accuracy=100.000/7.591, learning_rate=1.000e-04]\n","Training Epoch 70/1000: 100%|██████████| 4/4 [00:00<00:00, 25.93 batches/s, loss=2.637/9.648, train accuracy=92.857/7.453, learning_rate=1.000e-04]\n","Training Epoch 71/1000: 100%|██████████| 4/4 [00:00<00:00, 30.42 batches/s, loss=2.722/9.622, train accuracy=100.000/7.798, learning_rate=1.000e-04]\n","Training Epoch 72/1000: 100%|██████████| 4/4 [00:00<00:00, 31.02 batches/s, loss=2.626/9.588, train accuracy=100.000/7.039, learning_rate=1.000e-04]\n","Training Epoch 73/1000: 100%|██████████| 4/4 [00:00<00:00, 32.35 batches/s, loss=2.676/9.563, train accuracy=100.000/7.246, learning_rate=1.000e-04]\n","Training Epoch 74/1000: 100%|██████████| 4/4 [00:00<00:00, 26.35 batches/s, loss=2.499/9.499, train accuracy=100.000/7.522, learning_rate=1.000e-04]\n","Training Epoch 75/1000: 100%|██████████| 4/4 [00:00<00:00, 26.36 batches/s, loss=2.676/9.519, train accuracy=92.857/8.213, learning_rate=1.000e-04]\n","Training Epoch 76/1000: 100%|██████████| 4/4 [00:00<00:00, 30.59 batches/s, loss=2.724/9.450, train accuracy=92.857/8.075, learning_rate=1.000e-04]\n","Training Epoch 77/1000: 100%|██████████| 4/4 [00:00<00:00, 28.33 batches/s, loss=2.654/9.400, train accuracy=100.000/8.213, learning_rate=1.000e-04]\n","Training Epoch 78/1000: 100%|██████████| 4/4 [00:00<00:00, 31.37 batches/s, loss=2.553/9.441, train accuracy=100.000/8.282, learning_rate=1.000e-04]\n","Training Epoch 79/1000: 100%|██████████| 4/4 [00:00<00:00, 31.34 batches/s, loss=2.484/9.248, train accuracy=100.000/8.627, learning_rate=1.000e-04]\n","Training Epoch 80/1000: 100%|██████████| 4/4 [00:00<00:00, 30.43 batches/s, loss=2.529/9.234, train accuracy=92.857/7.867, learning_rate=1.000e-04]\n","Training Epoch 81/1000: 100%|██████████| 4/4 [00:00<00:00, 25.23 batches/s, loss=2.590/9.228, train accuracy=92.857/7.729, learning_rate=1.000e-04]\n","Training Epoch 82/1000: 100%|██████████| 4/4 [00:00<00:00, 24.01 batches/s, loss=2.588/9.201, train accuracy=100.000/8.006, learning_rate=1.000e-04]\n","Training Epoch 83/1000: 100%|██████████| 4/4 [00:00<00:00, 30.47 batches/s, loss=2.611/9.187, train accuracy=100.000/8.489, learning_rate=1.000e-04]\n","Training Epoch 84/1000: 100%|██████████| 4/4 [00:00<00:00, 29.04 batches/s, loss=2.518/9.137, train accuracy=100.000/7.867, learning_rate=1.000e-04]\n","Training Epoch 85/1000: 100%|██████████| 4/4 [00:00<00:00, 31.04 batches/s, loss=2.622/9.110, train accuracy=92.857/8.765, learning_rate=1.000e-04]\n","Training Epoch 86/1000: 100%|██████████| 4/4 [00:00<00:00, 28.36 batches/s, loss=2.678/9.072, train accuracy=92.857/8.282, learning_rate=1.000e-04]\n","Training Epoch 87/1000: 100%|██████████| 4/4 [00:00<00:00, 26.89 batches/s, loss=2.635/9.070, train accuracy=92.857/8.006, learning_rate=1.000e-04]\n","Training Epoch 88/1000: 100%|██████████| 4/4 [00:00<00:00, 24.16 batches/s, loss=2.467/9.000, train accuracy=100.000/8.903, learning_rate=1.000e-04]\n","Training Epoch 89/1000: 100%|██████████| 4/4 [00:00<00:00, 28.82 batches/s, loss=2.436/8.893, train accuracy=100.000/9.110, learning_rate=1.000e-04]\n","Training Epoch 90/1000: 100%|██████████| 4/4 [00:00<00:00, 29.21 batches/s, loss=2.570/8.948, train accuracy=92.857/8.834, learning_rate=1.000e-04]\n","Training Epoch 91/1000: 100%|██████████| 4/4 [00:00<00:00, 30.87 batches/s, loss=2.480/8.888, train accuracy=100.000/8.627, learning_rate=1.000e-04]\n","Training Epoch 92/1000: 100%|██████████| 4/4 [00:00<00:00, 31.04 batches/s, loss=2.471/8.873, train accuracy=100.000/9.110, learning_rate=1.000e-04]\n","Training Epoch 93/1000: 100%|██████████| 4/4 [00:00<00:00, 32.27 batches/s, loss=2.438/8.850, train accuracy=100.000/9.110, learning_rate=1.000e-04]\n","Training Epoch 94/1000: 100%|██████████| 4/4 [00:00<00:00, 29.78 batches/s, loss=2.427/8.737, train accuracy=100.000/9.317, learning_rate=1.000e-04]\n","Training Epoch 95/1000: 100%|██████████| 4/4 [00:00<00:00, 23.80 batches/s, loss=2.516/8.749, train accuracy=92.857/8.006, learning_rate=1.000e-04]\n","Training Epoch 96/1000: 100%|██████████| 4/4 [00:00<00:00, 29.30 batches/s, loss=2.486/8.721, train accuracy=100.000/9.524, learning_rate=1.000e-04]\n","Training Epoch 97/1000: 100%|██████████| 4/4 [00:00<00:00, 31.46 batches/s, loss=2.585/8.745, train accuracy=92.857/9.317, learning_rate=1.000e-04]\n","Training Epoch 98/1000: 100%|██████████| 4/4 [00:00<00:00, 28.39 batches/s, loss=2.473/8.669, train accuracy=100.000/8.903, learning_rate=1.000e-04]\n","Training Epoch 99/1000: 100%|██████████| 4/4 [00:00<00:00, 31.47 batches/s, loss=2.544/8.585, train accuracy=100.000/10.904, learning_rate=1.000e-04]\n","Training Epoch 100/1000: 100%|██████████| 4/4 [00:00<00:00, 27.99 batches/s, loss=2.531/8.560, train accuracy=100.000/9.869, learning_rate=1.000e-04]\n","Training Epoch 101/1000: 100%|██████████| 4/4 [00:00<00:00, 18.34 batches/s, loss=2.430/8.505, train accuracy=100.000/8.765, learning_rate=1.000e-04]\n","Training Epoch 102/1000: 100%|██████████| 4/4 [00:00<00:00, 20.15 batches/s, loss=2.336/8.508, train accuracy=100.000/9.386, learning_rate=1.000e-04]\n","Training Epoch 103/1000: 100%|██████████| 4/4 [00:00<00:00, 21.60 batches/s, loss=2.465/8.479, train accuracy=100.000/10.973, learning_rate=1.000e-04]\n","Training Epoch 104/1000: 100%|██████████| 4/4 [00:00<00:00, 20.55 batches/s, loss=2.430/8.420, train accuracy=100.000/9.524, learning_rate=1.000e-04]\n","Training Epoch 105/1000: 100%|██████████| 4/4 [00:00<00:00, 21.90 batches/s, loss=2.352/8.360, train accuracy=100.000/10.421, learning_rate=1.000e-04]\n","Training Epoch 106/1000: 100%|██████████| 4/4 [00:00<00:00, 20.14 batches/s, loss=2.398/8.356, train accuracy=100.000/9.248, learning_rate=1.000e-04]\n","Training Epoch 107/1000: 100%|██████████| 4/4 [00:00<00:00, 21.50 batches/s, loss=2.390/8.381, train accuracy=100.000/9.869, learning_rate=1.000e-04]\n","Training Epoch 108/1000: 100%|██████████| 4/4 [00:00<00:00, 21.14 batches/s, loss=2.395/8.308, train accuracy=100.000/9.800, learning_rate=1.000e-04]\n","Training Epoch 109/1000: 100%|██████████| 4/4 [00:00<00:00, 19.79 batches/s, loss=2.386/8.286, train accuracy=100.000/9.248, learning_rate=1.000e-04]\n","Training Epoch 110/1000: 100%|██████████| 4/4 [00:00<00:00, 20.96 batches/s, loss=2.375/8.249, train accuracy=100.000/10.697, learning_rate=1.000e-04]\n","Training Epoch 111/1000: 100%|██████████| 4/4 [00:00<00:00, 17.34 batches/s, loss=2.386/8.158, train accuracy=100.000/10.766, learning_rate=1.000e-04]\n","Training Epoch 112/1000: 100%|██████████| 4/4 [00:00<00:00, 19.45 batches/s, loss=2.349/8.191, train accuracy=100.000/10.007, learning_rate=1.000e-04]\n","Training Epoch 113/1000: 100%|██████████| 4/4 [00:00<00:00, 20.26 batches/s, loss=2.303/8.092, train accuracy=100.000/10.697, learning_rate=1.000e-04]\n","Training Epoch 114/1000: 100%|██████████| 4/4 [00:00<00:00, 19.85 batches/s, loss=2.350/8.074, train accuracy=100.000/10.835, learning_rate=1.000e-04]\n","Training Epoch 115/1000: 100%|██████████| 4/4 [00:00<00:00, 18.64 batches/s, loss=2.377/8.063, train accuracy=92.857/10.628, learning_rate=1.000e-04]\n","Training Epoch 116/1000: 100%|██████████| 4/4 [00:00<00:00, 18.13 batches/s, loss=2.357/8.062, train accuracy=100.000/9.662, learning_rate=1.000e-04]\n","Training Epoch 117/1000: 100%|██████████| 4/4 [00:00<00:00, 17.71 batches/s, loss=2.386/8.052, train accuracy=100.000/10.490, learning_rate=1.000e-04]\n","Training Epoch 118/1000: 100%|██████████| 4/4 [00:00<00:00, 25.26 batches/s, loss=2.390/7.986, train accuracy=100.000/10.490, learning_rate=1.000e-04]\n","Training Epoch 119/1000: 100%|██████████| 4/4 [00:00<00:00, 31.18 batches/s, loss=2.357/8.001, train accuracy=100.000/10.145, learning_rate=1.000e-04]\n","Training Epoch 120/1000: 100%|██████████| 4/4 [00:00<00:00, 31.55 batches/s, loss=2.373/7.914, train accuracy=100.000/10.766, learning_rate=1.000e-04]\n","Training Epoch 121/1000: 100%|██████████| 4/4 [00:00<00:00, 24.15 batches/s, loss=2.486/7.903, train accuracy=100.000/11.663, learning_rate=1.000e-04]\n","Training Epoch 122/1000: 100%|██████████| 4/4 [00:00<00:00, 29.22 batches/s, loss=2.247/7.799, train accuracy=100.000/12.836, learning_rate=1.000e-04]\n","Training Epoch 123/1000: 100%|██████████| 4/4 [00:00<00:00, 29.30 batches/s, loss=2.539/7.878, train accuracy=92.857/11.387, learning_rate=1.000e-04]\n","Training Epoch 124/1000: 100%|██████████| 4/4 [00:00<00:00, 30.87 batches/s, loss=2.262/7.781, train accuracy=100.000/11.732, learning_rate=1.000e-04]\n","Training Epoch 125/1000: 100%|██████████| 4/4 [00:00<00:00, 28.40 batches/s, loss=2.270/7.732, train accuracy=100.000/11.939, learning_rate=1.000e-04]\n","Training Epoch 126/1000: 100%|██████████| 4/4 [00:00<00:00, 30.55 batches/s, loss=2.308/7.729, train accuracy=100.000/10.973, learning_rate=1.000e-04]\n","Training Epoch 127/1000: 100%|██████████| 4/4 [00:00<00:00, 27.97 batches/s, loss=2.298/7.691, train accuracy=100.000/12.698, learning_rate=1.000e-04]\n","Training Epoch 128/1000: 100%|██████████| 4/4 [00:00<00:00, 24.11 batches/s, loss=2.235/7.694, train accuracy=100.000/10.421, learning_rate=1.000e-04]\n","Training Epoch 129/1000: 100%|██████████| 4/4 [00:00<00:00, 28.89 batches/s, loss=2.329/7.623, train accuracy=92.857/10.697, learning_rate=1.000e-04]\n","Training Epoch 130/1000: 100%|██████████| 4/4 [00:00<00:00, 29.73 batches/s, loss=2.440/7.640, train accuracy=100.000/12.560, learning_rate=1.000e-04]\n","Training Epoch 131/1000: 100%|██████████| 4/4 [00:00<00:00, 29.86 batches/s, loss=2.361/7.652, train accuracy=100.000/12.422, learning_rate=1.000e-04]\n","Training Epoch 132/1000: 100%|██████████| 4/4 [00:00<00:00, 25.48 batches/s, loss=2.309/7.611, train accuracy=100.000/12.560, learning_rate=1.000e-04]\n","Training Epoch 133/1000: 100%|██████████| 4/4 [00:00<00:00, 31.03 batches/s, loss=2.265/7.534, train accuracy=100.000/11.663, learning_rate=1.000e-04]\n","Training Epoch 134/1000: 100%|██████████| 4/4 [00:00<00:00, 25.34 batches/s, loss=2.271/7.570, train accuracy=100.000/11.732, learning_rate=1.000e-04]\n","Training Epoch 135/1000: 100%|██████████| 4/4 [00:00<00:00, 24.41 batches/s, loss=2.334/7.455, train accuracy=100.000/12.422, learning_rate=1.000e-04]\n","Training Epoch 136/1000: 100%|██████████| 4/4 [00:00<00:00, 29.80 batches/s, loss=2.405/7.495, train accuracy=92.857/13.043, learning_rate=1.000e-04]\n","Training Epoch 137/1000: 100%|██████████| 4/4 [00:00<00:00, 28.26 batches/s, loss=2.342/7.453, train accuracy=100.000/13.251, learning_rate=1.000e-04]\n","Training Epoch 138/1000: 100%|██████████| 4/4 [00:00<00:00, 29.17 batches/s, loss=2.236/7.385, train accuracy=100.000/12.836, learning_rate=1.000e-04]\n","Training Epoch 139/1000: 100%|██████████| 4/4 [00:00<00:00, 29.54 batches/s, loss=2.366/7.418, train accuracy=100.000/13.112, learning_rate=1.000e-04]\n","Training Epoch 140/1000: 100%|██████████| 4/4 [00:00<00:00, 29.52 batches/s, loss=2.254/7.360, train accuracy=100.000/13.112, learning_rate=1.000e-04]\n","Training Epoch 141/1000: 100%|██████████| 4/4 [00:00<00:00, 24.03 batches/s, loss=2.362/7.317, train accuracy=100.000/13.527, learning_rate=1.000e-04]\n","Training Epoch 142/1000: 100%|██████████| 4/4 [00:00<00:00, 26.79 batches/s, loss=2.333/7.297, train accuracy=100.000/13.112, learning_rate=1.000e-04]\n","Training Epoch 143/1000: 100%|██████████| 4/4 [00:00<00:00, 31.89 batches/s, loss=2.320/7.205, train accuracy=100.000/14.286, learning_rate=1.000e-04]\n","Training Epoch 144/1000: 100%|██████████| 4/4 [00:00<00:00, 29.48 batches/s, loss=2.367/7.297, train accuracy=100.000/13.665, learning_rate=1.000e-04]\n","Training Epoch 145/1000: 100%|██████████| 4/4 [00:00<00:00, 26.88 batches/s, loss=2.274/7.236, train accuracy=100.000/12.491, learning_rate=1.000e-04]\n","Training Epoch 146/1000: 100%|██████████| 4/4 [00:00<00:00, 26.70 batches/s, loss=2.271/7.192, train accuracy=100.000/14.286, learning_rate=1.000e-04]\n","Training Epoch 147/1000: 100%|██████████| 4/4 [00:00<00:00, 27.53 batches/s, loss=2.185/7.158, train accuracy=100.000/13.872, learning_rate=1.000e-04]\n","Training Epoch 148/1000: 100%|██████████| 4/4 [00:00<00:00, 23.22 batches/s, loss=2.210/7.121, train accuracy=100.000/13.251, learning_rate=1.000e-04]\n","Training Epoch 149/1000: 100%|██████████| 4/4 [00:00<00:00, 29.76 batches/s, loss=2.227/7.130, train accuracy=100.000/13.665, learning_rate=1.000e-04]\n","Training Epoch 150/1000: 100%|██████████| 4/4 [00:00<00:00, 30.01 batches/s, loss=2.153/7.088, train accuracy=100.000/14.769, learning_rate=1.000e-04]\n","Training Epoch 151/1000: 100%|██████████| 4/4 [00:00<00:00, 30.66 batches/s, loss=2.325/7.108, train accuracy=100.000/13.872, learning_rate=1.000e-04]\n","Training Epoch 152/1000: 100%|██████████| 4/4 [00:00<00:00, 28.60 batches/s, loss=2.247/7.026, train accuracy=100.000/15.045, learning_rate=1.000e-04]\n","Training Epoch 153/1000: 100%|██████████| 4/4 [00:00<00:00, 25.88 batches/s, loss=2.272/6.983, train accuracy=100.000/14.493, learning_rate=1.000e-04]\n","Training Epoch 154/1000: 100%|██████████| 4/4 [00:00<00:00, 22.65 batches/s, loss=2.204/6.998, train accuracy=100.000/14.286, learning_rate=1.000e-04]\n","Training Epoch 155/1000: 100%|██████████| 4/4 [00:00<00:00, 26.12 batches/s, loss=2.225/6.921, train accuracy=100.000/15.045, learning_rate=1.000e-04]\n","Training Epoch 156/1000: 100%|██████████| 4/4 [00:00<00:00, 29.51 batches/s, loss=2.120/6.902, train accuracy=100.000/14.217, learning_rate=1.000e-04]\n","Training Epoch 157/1000: 100%|██████████| 4/4 [00:00<00:00, 29.47 batches/s, loss=2.286/6.958, train accuracy=100.000/12.974, learning_rate=1.000e-04]\n","Training Epoch 158/1000: 100%|██████████| 4/4 [00:00<00:00, 31.12 batches/s, loss=2.212/6.887, train accuracy=100.000/15.252, learning_rate=1.000e-04]\n","Training Epoch 159/1000: 100%|██████████| 4/4 [00:00<00:00, 28.64 batches/s, loss=2.322/6.852, train accuracy=100.000/14.838, learning_rate=1.000e-04]\n","Training Epoch 160/1000: 100%|██████████| 4/4 [00:00<00:00, 25.61 batches/s, loss=2.139/6.808, train accuracy=100.000/15.666, learning_rate=1.000e-04]\n","Training Epoch 161/1000: 100%|██████████| 4/4 [00:00<00:00, 22.97 batches/s, loss=2.339/6.861, train accuracy=100.000/13.665, learning_rate=1.000e-04]\n","Training Epoch 162/1000: 100%|██████████| 4/4 [00:00<00:00, 31.28 batches/s, loss=2.204/6.776, train accuracy=100.000/15.804, learning_rate=1.000e-04]\n","Training Epoch 163/1000: 100%|██████████| 4/4 [00:00<00:00, 29.91 batches/s, loss=2.252/6.790, train accuracy=100.000/17.115, learning_rate=1.000e-04]\n","Training Epoch 164/1000: 100%|██████████| 4/4 [00:00<00:00, 31.91 batches/s, loss=2.215/6.737, train accuracy=100.000/14.769, learning_rate=1.000e-04]\n","Training Epoch 165/1000: 100%|██████████| 4/4 [00:00<00:00, 30.42 batches/s, loss=2.135/6.691, train accuracy=100.000/16.839, learning_rate=1.000e-04]\n","Training Epoch 166/1000: 100%|██████████| 4/4 [00:00<00:00, 28.96 batches/s, loss=2.118/6.680, train accuracy=100.000/15.735, learning_rate=1.000e-04]\n","Training Epoch 167/1000: 100%|██████████| 4/4 [00:00<00:00, 25.05 batches/s, loss=2.112/6.638, train accuracy=100.000/16.287, learning_rate=1.000e-04]\n","Training Epoch 168/1000: 100%|██████████| 4/4 [00:00<00:00, 25.84 batches/s, loss=2.133/6.619, train accuracy=100.000/16.287, learning_rate=1.000e-04]\n","Training Epoch 169/1000: 100%|██████████| 4/4 [00:00<00:00, 32.02 batches/s, loss=2.232/6.618, train accuracy=100.000/15.459, learning_rate=1.000e-04]\n","Training Epoch 170/1000: 100%|██████████| 4/4 [00:00<00:00, 30.09 batches/s, loss=2.156/6.592, train accuracy=100.000/16.563, learning_rate=1.000e-04]\n","Training Epoch 171/1000: 100%|██████████| 4/4 [00:00<00:00, 30.16 batches/s, loss=2.210/6.526, train accuracy=100.000/17.391, learning_rate=1.000e-04]\n","Training Epoch 172/1000: 100%|██████████| 4/4 [00:00<00:00, 31.64 batches/s, loss=2.219/6.546, train accuracy=100.000/16.011, learning_rate=1.000e-04]\n","Training Epoch 173/1000: 100%|██████████| 4/4 [00:00<00:00, 29.55 batches/s, loss=2.159/6.507, train accuracy=100.000/15.597, learning_rate=1.000e-04]\n","Training Epoch 174/1000: 100%|██████████| 4/4 [00:00<00:00, 22.68 batches/s, loss=2.141/6.484, train accuracy=100.000/17.046, learning_rate=1.000e-04]\n","Training Epoch 175/1000: 100%|██████████| 4/4 [00:00<00:00, 26.23 batches/s, loss=2.159/6.446, train accuracy=100.000/17.184, learning_rate=1.000e-04]\n","Training Epoch 176/1000: 100%|██████████| 4/4 [00:00<00:00, 30.81 batches/s, loss=2.098/6.439, train accuracy=100.000/17.598, learning_rate=1.000e-04]\n","Training Epoch 177/1000: 100%|██████████| 4/4 [00:00<00:00, 29.23 batches/s, loss=2.159/6.449, train accuracy=100.000/17.529, learning_rate=1.000e-04]\n","Training Epoch 178/1000: 100%|██████████| 4/4 [00:00<00:00, 30.80 batches/s, loss=2.081/6.388, train accuracy=100.000/16.632, learning_rate=1.000e-04]\n","Training Epoch 179/1000: 100%|██████████| 4/4 [00:00<00:00, 31.33 batches/s, loss=2.138/6.408, train accuracy=92.857/17.391, learning_rate=1.000e-04]\n","Training Epoch 180/1000: 100%|██████████| 4/4 [00:00<00:00, 26.31 batches/s, loss=2.363/6.445, train accuracy=92.857/16.701, learning_rate=1.000e-04]\n","Training Epoch 181/1000: 100%|██████████| 4/4 [00:00<00:00, 23.52 batches/s, loss=2.094/6.359, train accuracy=100.000/17.529, learning_rate=1.000e-04]\n","Training Epoch 182/1000: 100%|██████████| 4/4 [00:00<00:00, 29.87 batches/s, loss=2.115/6.326, train accuracy=100.000/18.565, learning_rate=1.000e-04]\n","Training Epoch 183/1000: 100%|██████████| 4/4 [00:00<00:00, 28.80 batches/s, loss=2.102/6.305, train accuracy=100.000/17.667, learning_rate=1.000e-04]\n","Training Epoch 184/1000: 100%|██████████| 4/4 [00:00<00:00, 27.66 batches/s, loss=2.113/6.299, train accuracy=100.000/17.184, learning_rate=1.000e-04]\n","Training Epoch 185/1000: 100%|██████████| 4/4 [00:00<00:00, 20.30 batches/s, loss=2.155/6.278, train accuracy=100.000/18.219, learning_rate=1.000e-04]\n","Training Epoch 186/1000: 100%|██████████| 4/4 [00:00<00:00, 17.82 batches/s, loss=2.077/6.209, train accuracy=100.000/17.598, learning_rate=1.000e-04]\n","Training Epoch 187/1000: 100%|██████████| 4/4 [00:00<00:00, 19.22 batches/s, loss=2.124/6.178, train accuracy=100.000/17.667, learning_rate=1.000e-04]\n","Training Epoch 188/1000: 100%|██████████| 4/4 [00:00<00:00, 21.58 batches/s, loss=2.116/6.168, train accuracy=100.000/17.943, learning_rate=1.000e-04]\n","Training Epoch 189/1000: 100%|██████████| 4/4 [00:00<00:00, 21.21 batches/s, loss=2.063/6.183, train accuracy=100.000/17.736, learning_rate=1.000e-04]\n","Training Epoch 190/1000: 100%|██████████| 4/4 [00:00<00:00, 23.56 batches/s, loss=2.210/6.187, train accuracy=92.857/18.496, learning_rate=1.000e-04]\n","Training Epoch 191/1000: 100%|██████████| 4/4 [00:00<00:00, 18.24 batches/s, loss=2.109/6.202, train accuracy=100.000/18.219, learning_rate=1.000e-04]\n","Training Epoch 192/1000: 100%|██████████| 4/4 [00:00<00:00, 20.47 batches/s, loss=2.073/6.104, train accuracy=100.000/18.772, learning_rate=1.000e-04]\n","Training Epoch 193/1000: 100%|██████████| 4/4 [00:00<00:00, 22.84 batches/s, loss=2.101/6.086, train accuracy=100.000/17.736, learning_rate=1.000e-04]\n","Training Epoch 194/1000: 100%|██████████| 4/4 [00:00<00:00, 21.37 batches/s, loss=2.114/6.043, train accuracy=100.000/19.186, learning_rate=1.000e-04]\n","Training Epoch 195/1000: 100%|██████████| 4/4 [00:00<00:00, 21.67 batches/s, loss=2.114/5.992, train accuracy=100.000/19.531, learning_rate=1.000e-04]\n","Training Epoch 196/1000: 100%|██████████| 4/4 [00:00<00:00, 15.32 batches/s, loss=2.108/6.033, train accuracy=100.000/18.427, learning_rate=1.000e-04]\n","Training Epoch 197/1000: 100%|██████████| 4/4 [00:00<00:00, 18.71 batches/s, loss=2.137/6.047, train accuracy=100.000/19.876, learning_rate=1.000e-04]\n","Training Epoch 198/1000: 100%|██████████| 4/4 [00:00<00:00, 19.54 batches/s, loss=2.030/5.986, train accuracy=100.000/18.910, learning_rate=1.000e-04]\n","Training Epoch 199/1000: 100%|██████████| 4/4 [00:00<00:00, 17.19 batches/s, loss=2.106/6.018, train accuracy=100.000/18.634, learning_rate=1.000e-04]\n","Training Epoch 200/1000: 100%|██████████| 4/4 [00:00<00:00, 16.50 batches/s, loss=2.066/5.961, train accuracy=100.000/20.635, learning_rate=1.000e-04]\n","Training Epoch 201/1000: 100%|██████████| 4/4 [00:00<00:00, 17.88 batches/s, loss=2.125/5.952, train accuracy=100.000/21.118, learning_rate=1.000e-04]\n","Training Epoch 202/1000: 100%|██████████| 4/4 [00:00<00:00, 19.36 batches/s, loss=2.068/5.920, train accuracy=100.000/20.497, learning_rate=1.000e-04]\n","Training Epoch 203/1000: 100%|██████████| 4/4 [00:00<00:00, 23.99 batches/s, loss=2.051/5.944, train accuracy=100.000/19.531, learning_rate=1.000e-04]\n","Training Epoch 204/1000: 100%|██████████| 4/4 [00:00<00:00, 28.99 batches/s, loss=2.018/5.868, train accuracy=100.000/20.014, learning_rate=1.000e-04]\n","Training Epoch 205/1000: 100%|██████████| 4/4 [00:00<00:00, 28.42 batches/s, loss=2.025/5.859, train accuracy=100.000/20.635, learning_rate=1.000e-04]\n","Training Epoch 206/1000: 100%|██████████| 4/4 [00:00<00:00, 23.45 batches/s, loss=2.012/5.778, train accuracy=100.000/20.704, learning_rate=1.000e-04]\n","Training Epoch 207/1000: 100%|██████████| 4/4 [00:00<00:00, 27.10 batches/s, loss=2.014/5.782, train accuracy=100.000/20.842, learning_rate=1.000e-04]\n","Training Epoch 208/1000: 100%|██████████| 4/4 [00:00<00:00, 30.09 batches/s, loss=2.131/5.853, train accuracy=100.000/20.842, learning_rate=1.000e-04]\n","Training Epoch 209/1000: 100%|██████████| 4/4 [00:00<00:00, 28.29 batches/s, loss=2.061/5.779, train accuracy=100.000/21.187, learning_rate=1.000e-04]\n","Training Epoch 210/1000: 100%|██████████| 4/4 [00:00<00:00, 30.86 batches/s, loss=2.087/5.824, train accuracy=100.000/20.290, learning_rate=1.000e-04]\n","Training Epoch 211/1000: 100%|██████████| 4/4 [00:00<00:00, 30.00 batches/s, loss=2.059/5.695, train accuracy=100.000/21.187, learning_rate=1.000e-04]\n","Training Epoch 212/1000: 100%|██████████| 4/4 [00:00<00:00, 26.80 batches/s, loss=1.984/5.714, train accuracy=100.000/21.463, learning_rate=1.000e-04]\n","Training Epoch 213/1000: 100%|██████████| 4/4 [00:00<00:00, 23.57 batches/s, loss=2.079/5.722, train accuracy=100.000/21.256, learning_rate=1.000e-04]\n","Training Epoch 214/1000: 100%|██████████| 4/4 [00:00<00:00, 26.26 batches/s, loss=2.050/5.739, train accuracy=100.000/20.635, learning_rate=1.000e-04]\n","Training Epoch 215/1000: 100%|██████████| 4/4 [00:00<00:00, 28.94 batches/s, loss=2.054/5.637, train accuracy=100.000/21.256, learning_rate=1.000e-04]\n","Training Epoch 216/1000: 100%|██████████| 4/4 [00:00<00:00, 30.98 batches/s, loss=2.064/5.632, train accuracy=100.000/22.222, learning_rate=1.000e-04]\n","Training Epoch 217/1000: 100%|██████████| 4/4 [00:00<00:00, 30.31 batches/s, loss=2.001/5.594, train accuracy=100.000/22.360, learning_rate=1.000e-04]\n","Training Epoch 218/1000: 100%|██████████| 4/4 [00:00<00:00, 31.75 batches/s, loss=2.030/5.582, train accuracy=100.000/22.153, learning_rate=1.000e-04]\n","Training Epoch 219/1000: 100%|██████████| 4/4 [00:00<00:00, 23.13 batches/s, loss=2.002/5.611, train accuracy=100.000/22.222, learning_rate=1.000e-04]\n","Training Epoch 220/1000: 100%|██████████| 4/4 [00:00<00:00, 28.75 batches/s, loss=1.996/5.576, train accuracy=100.000/20.773, learning_rate=1.000e-04]\n","Training Epoch 221/1000: 100%|██████████| 4/4 [00:00<00:00, 28.08 batches/s, loss=2.011/5.546, train accuracy=100.000/21.325, learning_rate=1.000e-04]\n","Training Epoch 222/1000: 100%|██████████| 4/4 [00:00<00:00, 30.54 batches/s, loss=1.988/5.549, train accuracy=100.000/22.567, learning_rate=1.000e-04]\n","Training Epoch 223/1000: 100%|██████████| 4/4 [00:00<00:00, 27.42 batches/s, loss=1.977/5.458, train accuracy=100.000/24.017, learning_rate=1.000e-04]\n","Training Epoch 224/1000: 100%|██████████| 4/4 [00:00<00:00, 29.49 batches/s, loss=2.104/5.550, train accuracy=100.000/22.429, learning_rate=1.000e-04]\n","Training Epoch 225/1000: 100%|██████████| 4/4 [00:00<00:00, 26.33 batches/s, loss=1.997/5.546, train accuracy=100.000/21.049, learning_rate=1.000e-04]\n","Training Epoch 226/1000: 100%|██████████| 4/4 [00:00<00:00, 22.37 batches/s, loss=2.036/5.452, train accuracy=100.000/23.671, learning_rate=1.000e-04]\n","Training Epoch 227/1000: 100%|██████████| 4/4 [00:00<00:00, 27.77 batches/s, loss=1.975/5.441, train accuracy=100.000/21.946, learning_rate=1.000e-04]\n","Training Epoch 228/1000: 100%|██████████| 4/4 [00:00<00:00, 29.45 batches/s, loss=2.110/5.447, train accuracy=100.000/23.326, learning_rate=1.000e-04]\n","Training Epoch 229/1000: 100%|██████████| 4/4 [00:00<00:00, 29.17 batches/s, loss=2.126/5.517, train accuracy=92.857/21.256, learning_rate=1.000e-04]\n","Training Epoch 230/1000: 100%|██████████| 4/4 [00:00<00:00, 29.51 batches/s, loss=2.042/5.378, train accuracy=100.000/23.464, learning_rate=1.000e-04]\n","Training Epoch 231/1000: 100%|██████████| 4/4 [00:00<00:00, 29.31 batches/s, loss=2.052/5.420, train accuracy=100.000/22.498, learning_rate=1.000e-04]\n","Training Epoch 232/1000: 100%|██████████| 4/4 [00:00<00:00, 22.85 batches/s, loss=2.053/5.362, train accuracy=100.000/23.464, learning_rate=1.000e-04]\n","Training Epoch 233/1000: 100%|██████████| 4/4 [00:00<00:00, 27.19 batches/s, loss=2.090/5.401, train accuracy=100.000/22.843, learning_rate=1.000e-04]\n","Training Epoch 234/1000: 100%|██████████| 4/4 [00:00<00:00, 25.75 batches/s, loss=1.969/5.282, train accuracy=100.000/24.569, learning_rate=1.000e-04]\n","Training Epoch 235/1000: 100%|██████████| 4/4 [00:00<00:00, 28.83 batches/s, loss=1.979/5.315, train accuracy=100.000/23.810, learning_rate=1.000e-04]\n","Training Epoch 236/1000: 100%|██████████| 4/4 [00:00<00:00, 29.08 batches/s, loss=1.985/5.263, train accuracy=100.000/24.224, learning_rate=1.000e-04]\n","Training Epoch 237/1000: 100%|██████████| 4/4 [00:00<00:00, 30.22 batches/s, loss=1.983/5.257, train accuracy=100.000/23.671, learning_rate=1.000e-04]\n","Training Epoch 238/1000: 100%|██████████| 4/4 [00:00<00:00, 24.17 batches/s, loss=2.113/5.314, train accuracy=100.000/23.050, learning_rate=1.000e-04]\n","Training Epoch 239/1000: 100%|██████████| 4/4 [00:00<00:00, 24.26 batches/s, loss=1.989/5.269, train accuracy=100.000/24.707, learning_rate=1.000e-04]\n","Training Epoch 240/1000: 100%|██████████| 4/4 [00:00<00:00, 28.74 batches/s, loss=1.938/5.240, train accuracy=100.000/23.533, learning_rate=1.000e-04]\n","Training Epoch 241/1000: 100%|██████████| 4/4 [00:00<00:00, 29.10 batches/s, loss=1.987/5.239, train accuracy=100.000/24.638, learning_rate=1.000e-04]\n","Training Epoch 242/1000: 100%|██████████| 4/4 [00:00<00:00, 29.59 batches/s, loss=1.973/5.205, train accuracy=100.000/24.983, learning_rate=1.000e-04]\n","Training Epoch 243/1000: 100%|██████████| 4/4 [00:00<00:00, 29.79 batches/s, loss=2.053/5.200, train accuracy=100.000/24.914, learning_rate=1.000e-04]\n","Training Epoch 244/1000: 100%|██████████| 4/4 [00:00<00:00, 28.66 batches/s, loss=1.991/5.162, train accuracy=100.000/26.915, learning_rate=1.000e-04]\n","Training Epoch 245/1000: 100%|██████████| 4/4 [00:00<00:00, 23.10 batches/s, loss=2.005/5.192, train accuracy=100.000/26.087, learning_rate=1.000e-04]\n","Training Epoch 246/1000: 100%|██████████| 4/4 [00:00<00:00, 27.64 batches/s, loss=1.944/5.149, train accuracy=100.000/24.707, learning_rate=1.000e-04]\n","Training Epoch 247/1000: 100%|██████████| 4/4 [00:00<00:00, 27.54 batches/s, loss=1.889/5.096, train accuracy=100.000/26.156, learning_rate=1.000e-04]\n","Training Epoch 248/1000: 100%|██████████| 4/4 [00:00<00:00, 28.31 batches/s, loss=1.950/5.104, train accuracy=100.000/26.087, learning_rate=1.000e-04]\n","Training Epoch 249/1000: 100%|██████████| 4/4 [00:00<00:00, 29.54 batches/s, loss=1.943/5.070, train accuracy=100.000/24.845, learning_rate=1.000e-04]\n","Training Epoch 250/1000: 100%|██████████| 4/4 [00:00<00:00, 28.74 batches/s, loss=1.923/5.051, train accuracy=100.000/25.397, learning_rate=1.000e-04]\n","Training Epoch 251/1000: 100%|██████████| 4/4 [00:00<00:00, 25.95 batches/s, loss=1.999/5.085, train accuracy=100.000/25.949, learning_rate=1.000e-04]\n","Training Epoch 252/1000: 100%|██████████| 4/4 [00:00<00:00, 23.07 batches/s, loss=1.936/5.027, train accuracy=100.000/26.639, learning_rate=1.000e-04]\n","Training Epoch 253/1000: 100%|██████████| 4/4 [00:00<00:00, 28.15 batches/s, loss=1.971/4.976, train accuracy=100.000/26.225, learning_rate=1.000e-04]\n","Training Epoch 254/1000: 100%|██████████| 4/4 [00:00<00:00, 25.41 batches/s, loss=1.970/4.975, train accuracy=100.000/27.122, learning_rate=1.000e-04]\n","Training Epoch 255/1000: 100%|██████████| 4/4 [00:00<00:00, 27.36 batches/s, loss=1.952/4.992, train accuracy=100.000/26.570, learning_rate=1.000e-04]\n","Training Epoch 256/1000: 100%|██████████| 4/4 [00:00<00:00, 28.91 batches/s, loss=1.950/4.951, train accuracy=100.000/27.467, learning_rate=1.000e-04]\n","Training Epoch 257/1000: 100%|██████████| 4/4 [00:00<00:00, 26.05 batches/s, loss=1.962/4.972, train accuracy=100.000/26.570, learning_rate=1.000e-04]\n","Training Epoch 258/1000: 100%|██████████| 4/4 [00:00<00:00, 24.41 batches/s, loss=1.907/4.931, train accuracy=100.000/26.846, learning_rate=1.000e-04]\n","Training Epoch 259/1000: 100%|██████████| 4/4 [00:00<00:00, 24.56 batches/s, loss=1.908/4.900, train accuracy=100.000/28.571, learning_rate=1.000e-04]\n","Training Epoch 260/1000: 100%|██████████| 4/4 [00:00<00:00, 27.31 batches/s, loss=1.945/4.910, train accuracy=100.000/27.191, learning_rate=1.000e-04]\n","Training Epoch 261/1000: 100%|██████████| 4/4 [00:00<00:00, 27.92 batches/s, loss=1.931/4.858, train accuracy=100.000/28.019, learning_rate=1.000e-04]\n","Training Epoch 262/1000: 100%|██████████| 4/4 [00:00<00:00, 26.94 batches/s, loss=1.906/4.849, train accuracy=100.000/28.640, learning_rate=1.000e-04]\n","Training Epoch 263/1000: 100%|██████████| 4/4 [00:00<00:00, 28.40 batches/s, loss=1.900/4.803, train accuracy=100.000/28.433, learning_rate=1.000e-04]\n","Training Epoch 264/1000: 100%|██████████| 4/4 [00:00<00:00, 23.16 batches/s, loss=1.944/4.860, train accuracy=100.000/27.191, learning_rate=1.000e-04]\n","Training Epoch 265/1000: 100%|██████████| 4/4 [00:00<00:00, 24.39 batches/s, loss=1.915/4.845, train accuracy=100.000/28.226, learning_rate=1.000e-04]\n","Training Epoch 266/1000: 100%|██████████| 4/4 [00:00<00:00, 29.31 batches/s, loss=1.914/4.805, train accuracy=100.000/27.260, learning_rate=1.000e-04]\n","Training Epoch 267/1000: 100%|██████████| 4/4 [00:00<00:00, 24.58 batches/s, loss=1.954/4.797, train accuracy=100.000/28.640, learning_rate=1.000e-04]\n","Training Epoch 268/1000: 100%|██████████| 4/4 [00:00<00:00, 20.29 batches/s, loss=1.897/4.763, train accuracy=100.000/28.226, learning_rate=1.000e-04]\n","Training Epoch 269/1000: 100%|██████████| 4/4 [00:00<00:00, 18.05 batches/s, loss=1.985/4.809, train accuracy=100.000/28.019, learning_rate=1.000e-04]\n","Training Epoch 270/1000: 100%|██████████| 4/4 [00:00<00:00, 19.86 batches/s, loss=1.900/4.775, train accuracy=100.000/28.916, learning_rate=1.000e-04]\n","Training Epoch 271/1000: 100%|██████████| 4/4 [00:00<00:00, 22.59 batches/s, loss=1.867/4.719, train accuracy=100.000/29.676, learning_rate=1.000e-04]\n","Training Epoch 272/1000: 100%|██████████| 4/4 [00:00<00:00, 21.59 batches/s, loss=1.934/4.708, train accuracy=100.000/28.709, learning_rate=1.000e-04]\n","Training Epoch 273/1000: 100%|██████████| 4/4 [00:00<00:00, 24.37 batches/s, loss=1.971/4.747, train accuracy=100.000/29.952, learning_rate=1.000e-04]\n","Training Epoch 274/1000: 100%|██████████| 4/4 [00:00<00:00,  6.06 batches/s, loss=1.889/4.739, train accuracy=100.000/27.674, learning_rate=1.000e-04]\n","Training Epoch 275/1000: 100%|██████████| 4/4 [00:00<00:00,  8.19 batches/s, loss=1.903/4.670, train accuracy=100.000/27.674, learning_rate=1.000e-04]\n","Training Epoch 276/1000: 100%|██████████| 4/4 [00:00<00:00, 23.79 batches/s, loss=1.875/4.648, train accuracy=100.000/29.952, learning_rate=1.000e-04]\n","Training Epoch 277/1000: 100%|██████████| 4/4 [00:00<00:00, 22.84 batches/s, loss=1.865/4.662, train accuracy=100.000/28.019, learning_rate=1.000e-04]\n","Training Epoch 278/1000: 100%|██████████| 4/4 [00:00<00:00, 18.52 batches/s, loss=1.883/4.639, train accuracy=100.000/30.780, learning_rate=1.000e-04]\n","Training Epoch 279/1000: 100%|██████████| 4/4 [00:00<00:00, 16.72 batches/s, loss=1.957/4.628, train accuracy=100.000/31.125, learning_rate=1.000e-04]\n","Training Epoch 280/1000: 100%|██████████| 4/4 [00:00<00:00, 17.40 batches/s, loss=1.878/4.632, train accuracy=100.000/29.469, learning_rate=1.000e-04]\n","Training Epoch 281/1000: 100%|██████████| 4/4 [00:00<00:00, 17.56 batches/s, loss=1.873/4.589, train accuracy=100.000/30.228, learning_rate=1.000e-04]\n","Training Epoch 282/1000: 100%|██████████| 4/4 [00:00<00:00, 17.28 batches/s, loss=1.886/4.634, train accuracy=100.000/28.364, learning_rate=1.000e-04]\n","Training Epoch 283/1000: 100%|██████████| 4/4 [00:00<00:00, 15.94 batches/s, loss=1.873/4.593, train accuracy=100.000/29.883, learning_rate=1.000e-04]\n","Training Epoch 284/1000: 100%|██████████| 4/4 [00:00<00:00, 15.93 batches/s, loss=1.936/4.566, train accuracy=100.000/31.746, learning_rate=1.000e-04]\n","Training Epoch 285/1000: 100%|██████████| 4/4 [00:00<00:00, 24.83 batches/s, loss=1.947/4.571, train accuracy=100.000/31.194, learning_rate=1.000e-04]\n","Training Epoch 286/1000: 100%|██████████| 4/4 [00:00<00:00, 26.13 batches/s, loss=1.879/4.500, train accuracy=100.000/32.298, learning_rate=1.000e-04]\n","Training Epoch 287/1000: 100%|██████████| 4/4 [00:00<00:00, 27.52 batches/s, loss=1.870/4.515, train accuracy=100.000/30.918, learning_rate=1.000e-04]\n","Training Epoch 288/1000: 100%|██████████| 4/4 [00:00<00:00, 25.59 batches/s, loss=1.855/4.490, train accuracy=100.000/31.953, learning_rate=1.000e-04]\n","Training Epoch 289/1000: 100%|██████████| 4/4 [00:00<00:00, 26.54 batches/s, loss=1.903/4.477, train accuracy=100.000/31.884, learning_rate=1.000e-04]\n","Training Epoch 290/1000: 100%|██████████| 4/4 [00:00<00:00, 22.99 batches/s, loss=1.867/4.476, train accuracy=100.000/31.332, learning_rate=1.000e-04]\n","Training Epoch 291/1000: 100%|██████████| 4/4 [00:00<00:00, 23.86 batches/s, loss=1.847/4.454, train accuracy=100.000/31.815, learning_rate=1.000e-04]\n","Training Epoch 292/1000: 100%|██████████| 4/4 [00:00<00:00, 27.05 batches/s, loss=1.883/4.461, train accuracy=100.000/32.643, learning_rate=1.000e-04]\n","Training Epoch 293/1000: 100%|██████████| 4/4 [00:00<00:00, 27.80 batches/s, loss=1.886/4.453, train accuracy=100.000/30.987, learning_rate=1.000e-04]\n","Training Epoch 294/1000: 100%|██████████| 4/4 [00:00<00:00, 25.78 batches/s, loss=1.938/4.424, train accuracy=100.000/32.298, learning_rate=1.000e-04]\n","Training Epoch 295/1000: 100%|██████████| 4/4 [00:00<00:00, 24.62 batches/s, loss=1.838/4.385, train accuracy=100.000/33.333, learning_rate=1.000e-04]\n","Training Epoch 296/1000: 100%|██████████| 4/4 [00:00<00:00, 21.49 batches/s, loss=1.857/4.405, train accuracy=100.000/33.402, learning_rate=1.000e-04]\n","Training Epoch 297/1000: 100%|██████████| 4/4 [00:00<00:00, 26.38 batches/s, loss=1.840/4.359, train accuracy=100.000/33.195, learning_rate=1.000e-04]\n","Training Epoch 298/1000: 100%|██████████| 4/4 [00:00<00:00, 27.62 batches/s, loss=1.863/4.336, train accuracy=100.000/32.298, learning_rate=1.000e-04]\n","Training Epoch 299/1000: 100%|██████████| 4/4 [00:00<00:00, 26.85 batches/s, loss=1.929/4.391, train accuracy=100.000/32.505, learning_rate=1.000e-04]\n","Training Epoch 300/1000: 100%|██████████| 4/4 [00:00<00:00, 27.57 batches/s, loss=1.908/4.320, train accuracy=100.000/34.023, learning_rate=1.000e-04]\n","Training Epoch 301/1000: 100%|██████████| 4/4 [00:00<00:00, 25.54 batches/s, loss=1.916/4.325, train accuracy=100.000/34.092, learning_rate=1.000e-04]\n","Training Epoch 302/1000: 100%|██████████| 4/4 [00:00<00:00, 23.67 batches/s, loss=1.934/4.340, train accuracy=92.857/33.678, learning_rate=1.000e-04]\n","Training Epoch 303/1000: 100%|██████████| 4/4 [00:00<00:00, 24.23 batches/s, loss=1.885/4.329, train accuracy=100.000/33.540, learning_rate=1.000e-04]\n","Training Epoch 304/1000: 100%|██████████| 4/4 [00:00<00:00, 27.34 batches/s, loss=1.943/4.300, train accuracy=100.000/34.300, learning_rate=1.000e-04]\n","Training Epoch 305/1000: 100%|██████████| 4/4 [00:00<00:00, 27.66 batches/s, loss=1.861/4.274, train accuracy=100.000/34.576, learning_rate=1.000e-04]\n","Training Epoch 306/1000: 100%|██████████| 4/4 [00:00<00:00, 27.34 batches/s, loss=1.892/4.255, train accuracy=100.000/34.645, learning_rate=1.000e-04]\n","Training Epoch 307/1000: 100%|██████████| 4/4 [00:00<00:00, 27.06 batches/s, loss=1.906/4.249, train accuracy=100.000/33.816, learning_rate=1.000e-04]\n","Training Epoch 308/1000: 100%|██████████| 4/4 [00:00<00:00, 24.49 batches/s, loss=1.903/4.244, train accuracy=100.000/35.473, learning_rate=1.000e-04]\n","Training Epoch 309/1000: 100%|██████████| 4/4 [00:00<00:00, 23.19 batches/s, loss=1.967/4.250, train accuracy=100.000/35.266, learning_rate=1.000e-04]\n","Training Epoch 310/1000: 100%|██████████| 4/4 [00:00<00:00, 25.49 batches/s, loss=1.851/4.226, train accuracy=100.000/33.885, learning_rate=1.000e-04]\n","Training Epoch 311/1000: 100%|██████████| 4/4 [00:00<00:00, 23.82 batches/s, loss=1.883/4.226, train accuracy=100.000/34.161, learning_rate=1.000e-04]\n","Training Epoch 312/1000: 100%|██████████| 4/4 [00:00<00:00, 26.54 batches/s, loss=1.892/4.184, train accuracy=100.000/34.990, learning_rate=1.000e-04]\n","Training Epoch 313/1000: 100%|██████████| 4/4 [00:00<00:00, 23.72 batches/s, loss=1.859/4.174, train accuracy=100.000/35.197, learning_rate=1.000e-04]\n","Training Epoch 314/1000: 100%|██████████| 4/4 [00:00<00:00, 22.14 batches/s, loss=1.829/4.128, train accuracy=100.000/36.232, learning_rate=1.000e-04]\n","Training Epoch 315/1000: 100%|██████████| 4/4 [00:00<00:00, 24.56 batches/s, loss=1.900/4.147, train accuracy=100.000/36.301, learning_rate=1.000e-04]\n","Training Epoch 316/1000: 100%|██████████| 4/4 [00:00<00:00, 27.83 batches/s, loss=1.849/4.114, train accuracy=100.000/37.129, learning_rate=1.000e-04]\n","Training Epoch 317/1000: 100%|██████████| 4/4 [00:00<00:00, 27.74 batches/s, loss=1.847/4.071, train accuracy=100.000/36.853, learning_rate=1.000e-04]\n","Training Epoch 318/1000: 100%|██████████| 4/4 [00:00<00:00, 28.00 batches/s, loss=1.895/4.112, train accuracy=100.000/35.542, learning_rate=1.000e-04]\n","Training Epoch 319/1000: 100%|██████████| 4/4 [00:00<00:00, 25.66 batches/s, loss=1.871/4.097, train accuracy=100.000/36.025, learning_rate=1.000e-04]\n","Training Epoch 320/1000: 100%|██████████| 4/4 [00:00<00:00, 23.39 batches/s, loss=1.896/4.109, train accuracy=100.000/36.025, learning_rate=1.000e-04]\n","Training Epoch 321/1000: 100%|██████████| 4/4 [00:00<00:00, 23.77 batches/s, loss=1.808/4.074, train accuracy=100.000/36.508, learning_rate=1.000e-04]\n","Training Epoch 322/1000: 100%|██████████| 4/4 [00:00<00:00, 26.49 batches/s, loss=1.856/4.060, train accuracy=100.000/37.267, learning_rate=1.000e-04]\n","Training Epoch 323/1000: 100%|██████████| 4/4 [00:00<00:00, 27.78 batches/s, loss=1.848/4.000, train accuracy=100.000/37.750, learning_rate=1.000e-04]\n","Training Epoch 324/1000: 100%|██████████| 4/4 [00:00<00:00, 27.21 batches/s, loss=1.842/4.038, train accuracy=100.000/37.957, learning_rate=1.000e-04]\n","Training Epoch 325/1000: 100%|██████████| 4/4 [00:00<00:00, 27.37 batches/s, loss=1.845/4.038, train accuracy=100.000/38.164, learning_rate=1.000e-04]\n","Training Epoch 326/1000: 100%|██████████| 4/4 [00:00<00:00, 22.07 batches/s, loss=1.862/3.989, train accuracy=100.000/38.440, learning_rate=1.000e-04]\n","Training Epoch 327/1000: 100%|██████████| 4/4 [00:00<00:00, 21.61 batches/s, loss=1.853/4.002, train accuracy=100.000/37.750, learning_rate=1.000e-04]\n","Training Epoch 328/1000: 100%|██████████| 4/4 [00:00<00:00, 26.24 batches/s, loss=1.883/3.982, train accuracy=100.000/37.681, learning_rate=1.000e-04]\n","Training Epoch 329/1000: 100%|██████████| 4/4 [00:00<00:00, 26.98 batches/s, loss=1.817/4.001, train accuracy=100.000/38.164, learning_rate=1.000e-04]\n","Training Epoch 330/1000: 100%|██████████| 4/4 [00:00<00:00, 26.97 batches/s, loss=1.846/3.969, train accuracy=100.000/37.543, learning_rate=1.000e-04]\n","Training Epoch 331/1000: 100%|██████████| 4/4 [00:00<00:00, 27.45 batches/s, loss=1.823/3.956, train accuracy=100.000/38.785, learning_rate=1.000e-04]\n","Training Epoch 332/1000: 100%|██████████| 4/4 [00:00<00:00, 21.48 batches/s, loss=2.010/3.991, train accuracy=100.000/36.922, learning_rate=1.000e-04]\n","Training Epoch 333/1000: 100%|██████████| 4/4 [00:00<00:00, 23.06 batches/s, loss=1.873/3.913, train accuracy=100.000/39.130, learning_rate=1.000e-04]\n","Training Epoch 334/1000: 100%|██████████| 4/4 [00:00<00:00, 26.61 batches/s, loss=1.872/3.964, train accuracy=100.000/37.750, learning_rate=1.000e-04]\n","Training Epoch 335/1000: 100%|██████████| 4/4 [00:00<00:00, 27.97 batches/s, loss=1.831/3.903, train accuracy=100.000/38.509, learning_rate=1.000e-04]\n","Training Epoch 336/1000: 100%|██████████| 4/4 [00:00<00:00, 26.60 batches/s, loss=1.861/3.910, train accuracy=100.000/39.199, learning_rate=1.000e-04]\n","Training Epoch 337/1000: 100%|██████████| 4/4 [00:00<00:00, 26.36 batches/s, loss=1.827/3.903, train accuracy=100.000/38.716, learning_rate=1.000e-04]\n","Training Epoch 338/1000: 100%|██████████| 4/4 [00:00<00:00, 20.97 batches/s, loss=1.814/3.870, train accuracy=100.000/38.164, learning_rate=1.000e-04]\n","Training Epoch 339/1000: 100%|██████████| 4/4 [00:00<00:00, 22.70 batches/s, loss=1.783/3.816, train accuracy=100.000/41.132, learning_rate=1.000e-04]\n","Training Epoch 340/1000: 100%|██████████| 4/4 [00:00<00:00, 26.71 batches/s, loss=1.828/3.850, train accuracy=100.000/39.130, learning_rate=1.000e-04]\n","Training Epoch 341/1000: 100%|██████████| 4/4 [00:00<00:00, 26.30 batches/s, loss=1.859/3.853, train accuracy=100.000/39.959, learning_rate=1.000e-04]\n","Training Epoch 342/1000: 100%|██████████| 4/4 [00:00<00:00, 27.08 batches/s, loss=1.884/3.858, train accuracy=100.000/39.752, learning_rate=1.000e-04]\n","Training Epoch 343/1000: 100%|██████████| 4/4 [00:00<00:00, 25.76 batches/s, loss=1.757/3.771, train accuracy=100.000/40.373, learning_rate=1.000e-04]\n","Training Epoch 344/1000: 100%|██████████| 4/4 [00:00<00:00, 18.07 batches/s, loss=1.813/3.802, train accuracy=100.000/40.304, learning_rate=1.000e-04]\n","Training Epoch 345/1000: 100%|██████████| 4/4 [00:00<00:00, 18.55 batches/s, loss=1.820/3.775, train accuracy=100.000/39.959, learning_rate=1.000e-04]\n","Training Epoch 346/1000: 100%|██████████| 4/4 [00:00<00:00, 20.44 batches/s, loss=1.837/3.802, train accuracy=100.000/39.959, learning_rate=1.000e-04]\n","Training Epoch 347/1000: 100%|██████████| 4/4 [00:00<00:00, 19.35 batches/s, loss=1.802/3.776, train accuracy=100.000/40.580, learning_rate=1.000e-04]\n","Training Epoch 348/1000: 100%|██████████| 4/4 [00:00<00:00, 16.60 batches/s, loss=1.813/3.734, train accuracy=100.000/41.615, learning_rate=1.000e-04]\n","Training Epoch 349/1000: 100%|██████████| 4/4 [00:00<00:00, 17.69 batches/s, loss=1.847/3.735, train accuracy=100.000/41.063, learning_rate=1.000e-04]\n","Training Epoch 350/1000: 100%|██████████| 4/4 [00:00<00:00, 20.41 batches/s, loss=1.778/3.713, train accuracy=100.000/42.305, learning_rate=1.000e-04]\n","Training Epoch 351/1000: 100%|██████████| 4/4 [00:00<00:00, 18.96 batches/s, loss=1.770/3.735, train accuracy=100.000/41.201, learning_rate=1.000e-04]\n","Training Epoch 352/1000: 100%|██████████| 4/4 [00:00<00:00, 19.16 batches/s, loss=1.781/3.694, train accuracy=100.000/41.201, learning_rate=1.000e-04]\n","Training Epoch 353/1000: 100%|██████████| 4/4 [00:00<00:00, 17.33 batches/s, loss=1.807/3.708, train accuracy=100.000/41.822, learning_rate=1.000e-04]\n","Training Epoch 354/1000: 100%|██████████| 4/4 [00:00<00:00, 20.44 batches/s, loss=1.783/3.658, train accuracy=100.000/42.995, learning_rate=1.000e-04]\n","Training Epoch 355/1000: 100%|██████████| 4/4 [00:00<00:00, 17.67 batches/s, loss=1.767/3.679, train accuracy=100.000/43.892, learning_rate=1.000e-04]\n","Training Epoch 356/1000: 100%|██████████| 4/4 [00:00<00:00, 16.83 batches/s, loss=1.846/3.664, train accuracy=100.000/42.857, learning_rate=1.000e-04]\n","Training Epoch 357/1000: 100%|██████████| 4/4 [00:00<00:00, 15.52 batches/s, loss=1.792/3.685, train accuracy=100.000/42.443, learning_rate=1.000e-04]\n","Training Epoch 358/1000: 100%|██████████| 4/4 [00:00<00:00, 15.01 batches/s, loss=1.770/3.634, train accuracy=100.000/43.202, learning_rate=1.000e-04]\n","Training Epoch 359/1000: 100%|██████████| 4/4 [00:00<00:00, 17.53 batches/s, loss=1.814/3.665, train accuracy=100.000/42.029, learning_rate=1.000e-04]\n","Training Epoch 360/1000: 100%|██████████| 4/4 [00:00<00:00, 17.99 batches/s, loss=1.826/3.625, train accuracy=100.000/43.961, learning_rate=1.000e-04]\n","Training Epoch 361/1000: 100%|██████████| 4/4 [00:00<00:00, 16.97 batches/s, loss=1.761/3.590, train accuracy=100.000/42.788, learning_rate=1.000e-04]\n","Training Epoch 362/1000: 100%|██████████| 4/4 [00:00<00:00, 15.41 batches/s, loss=1.784/3.616, train accuracy=100.000/43.133, learning_rate=1.000e-04]\n","Training Epoch 363/1000: 100%|██████████| 4/4 [00:00<00:00, 15.02 batches/s, loss=1.789/3.635, train accuracy=100.000/42.719, learning_rate=1.000e-04]\n","Training Epoch 364/1000: 100%|██████████| 4/4 [00:00<00:00, 25.95 batches/s, loss=1.766/3.575, train accuracy=100.000/43.616, learning_rate=1.000e-04]\n","Training Epoch 365/1000: 100%|██████████| 4/4 [00:00<00:00, 23.51 batches/s, loss=1.832/3.575, train accuracy=100.000/43.547, learning_rate=1.000e-04]\n","Training Epoch 366/1000: 100%|██████████| 4/4 [00:00<00:00, 23.02 batches/s, loss=1.807/3.600, train accuracy=100.000/42.926, learning_rate=1.000e-04]\n","Training Epoch 367/1000: 100%|██████████| 4/4 [00:00<00:00, 25.07 batches/s, loss=1.817/3.558, train accuracy=100.000/44.237, learning_rate=1.000e-04]\n","Training Epoch 368/1000: 100%|██████████| 4/4 [00:00<00:00, 27.47 batches/s, loss=1.817/3.553, train accuracy=100.000/44.651, learning_rate=1.000e-04]\n","Training Epoch 369/1000: 100%|██████████| 4/4 [00:00<00:00, 26.26 batches/s, loss=1.788/3.513, train accuracy=100.000/45.549, learning_rate=1.000e-04]\n","Training Epoch 370/1000: 100%|██████████| 4/4 [00:00<00:00, 26.24 batches/s, loss=1.811/3.543, train accuracy=100.000/44.928, learning_rate=1.000e-04]\n","Training Epoch 371/1000: 100%|██████████| 4/4 [00:00<00:00, 26.03 batches/s, loss=1.777/3.489, train accuracy=100.000/46.791, learning_rate=1.000e-04]\n","Training Epoch 372/1000: 100%|██████████| 4/4 [00:00<00:00, 21.91 batches/s, loss=1.863/3.521, train accuracy=100.000/46.653, learning_rate=1.000e-04]\n","Training Epoch 373/1000: 100%|██████████| 4/4 [00:00<00:00, 23.02 batches/s, loss=1.824/3.522, train accuracy=100.000/44.997, learning_rate=1.000e-04]\n","Training Epoch 374/1000: 100%|██████████| 4/4 [00:00<00:00, 26.33 batches/s, loss=1.783/3.472, train accuracy=100.000/44.720, learning_rate=1.000e-04]\n","Training Epoch 375/1000: 100%|██████████| 4/4 [00:00<00:00, 25.81 batches/s, loss=1.909/3.518, train accuracy=100.000/45.549, learning_rate=1.000e-04]\n","Training Epoch 376/1000: 100%|██████████| 4/4 [00:00<00:00, 26.52 batches/s, loss=1.807/3.518, train accuracy=100.000/44.582, learning_rate=1.000e-04]\n","Training Epoch 377/1000: 100%|██████████| 4/4 [00:00<00:00, 22.87 batches/s, loss=1.818/3.487, train accuracy=100.000/45.204, learning_rate=1.000e-04]\n","Training Epoch 378/1000: 100%|██████████| 4/4 [00:00<00:00, 23.89 batches/s, loss=1.791/3.471, train accuracy=100.000/46.308, learning_rate=1.000e-04]\n","Training Epoch 379/1000: 100%|██████████| 4/4 [00:00<00:00, 25.75 batches/s, loss=1.737/3.447, train accuracy=100.000/46.170, learning_rate=1.000e-04]\n","Training Epoch 380/1000: 100%|██████████| 4/4 [00:00<00:00, 25.96 batches/s, loss=1.756/3.428, train accuracy=100.000/46.722, learning_rate=1.000e-04]\n","Training Epoch 381/1000: 100%|██████████| 4/4 [00:00<00:00, 25.92 batches/s, loss=1.778/3.395, train accuracy=100.000/48.723, learning_rate=1.000e-04]\n","Training Epoch 382/1000: 100%|██████████| 4/4 [00:00<00:00, 27.43 batches/s, loss=1.798/3.422, train accuracy=100.000/47.136, learning_rate=1.000e-04]\n","Training Epoch 383/1000: 100%|██████████| 4/4 [00:00<00:00, 23.84 batches/s, loss=1.784/3.414, train accuracy=100.000/46.998, learning_rate=1.000e-04]\n","Training Epoch 384/1000: 100%|██████████| 4/4 [00:00<00:00, 22.83 batches/s, loss=1.763/3.387, train accuracy=100.000/46.860, learning_rate=1.000e-04]\n","Training Epoch 385/1000: 100%|██████████| 4/4 [00:00<00:00, 26.47 batches/s, loss=1.754/3.378, train accuracy=100.000/47.757, learning_rate=1.000e-04]\n","Training Epoch 386/1000: 100%|██████████| 4/4 [00:00<00:00, 24.08 batches/s, loss=1.881/3.418, train accuracy=100.000/47.757, learning_rate=1.000e-04]\n","Training Epoch 387/1000: 100%|██████████| 4/4 [00:00<00:00, 26.82 batches/s, loss=1.794/3.371, train accuracy=100.000/47.205, learning_rate=1.000e-04]\n","Training Epoch 388/1000: 100%|██████████| 4/4 [00:00<00:00, 26.06 batches/s, loss=1.829/3.396, train accuracy=100.000/47.895, learning_rate=1.000e-04]\n","Training Epoch 389/1000: 100%|██████████| 4/4 [00:00<00:00, 23.50 batches/s, loss=1.777/3.361, train accuracy=100.000/48.792, learning_rate=1.000e-04]\n","Training Epoch 390/1000: 100%|██████████| 4/4 [00:00<00:00, 22.85 batches/s, loss=1.718/3.365, train accuracy=100.000/47.205, learning_rate=1.000e-04]\n","Training Epoch 391/1000: 100%|██████████| 4/4 [00:00<00:00, 25.64 batches/s, loss=1.790/3.313, train accuracy=100.000/48.792, learning_rate=1.000e-04]\n","Training Epoch 392/1000: 100%|██████████| 4/4 [00:00<00:00, 24.49 batches/s, loss=1.734/3.312, train accuracy=100.000/49.620, learning_rate=1.000e-04]\n","Training Epoch 393/1000: 100%|██████████| 4/4 [00:00<00:00, 26.71 batches/s, loss=1.740/3.308, train accuracy=100.000/48.930, learning_rate=1.000e-04]\n","Training Epoch 394/1000: 100%|██████████| 4/4 [00:00<00:00, 25.93 batches/s, loss=1.833/3.313, train accuracy=100.000/49.620, learning_rate=1.000e-04]\n","Training Epoch 395/1000: 100%|██████████| 4/4 [00:00<00:00, 22.62 batches/s, loss=1.745/3.284, train accuracy=100.000/49.137, learning_rate=1.000e-04]\n","Training Epoch 396/1000: 100%|██████████| 4/4 [00:00<00:00, 23.88 batches/s, loss=1.741/3.271, train accuracy=100.000/50.035, learning_rate=1.000e-04]\n","Training Epoch 397/1000: 100%|██████████| 4/4 [00:00<00:00, 26.45 batches/s, loss=1.777/3.292, train accuracy=100.000/48.861, learning_rate=1.000e-04]\n","Training Epoch 398/1000: 100%|██████████| 4/4 [00:00<00:00, 24.35 batches/s, loss=1.840/3.303, train accuracy=100.000/48.999, learning_rate=1.000e-04]\n","Training Epoch 399/1000: 100%|██████████| 4/4 [00:00<00:00, 26.62 batches/s, loss=1.726/3.241, train accuracy=100.000/49.551, learning_rate=1.000e-04]\n","Training Epoch 400/1000: 100%|██████████| 4/4 [00:00<00:00, 26.26 batches/s, loss=1.741/3.258, train accuracy=100.000/49.344, learning_rate=1.000e-04]\n","Training Epoch 401/1000: 100%|██████████| 4/4 [00:00<00:00, 22.06 batches/s, loss=1.809/3.251, train accuracy=100.000/51.829, learning_rate=1.000e-04]\n","Training Epoch 402/1000: 100%|██████████| 4/4 [00:00<00:00, 23.87 batches/s, loss=1.722/3.226, train accuracy=100.000/51.622, learning_rate=1.000e-04]\n","Training Epoch 403/1000: 100%|██████████| 4/4 [00:00<00:00, 26.49 batches/s, loss=1.778/3.222, train accuracy=100.000/51.622, learning_rate=1.000e-04]\n","Training Epoch 404/1000: 100%|██████████| 4/4 [00:00<00:00, 24.18 batches/s, loss=1.769/3.213, train accuracy=100.000/50.518, learning_rate=1.000e-04]\n","Training Epoch 405/1000: 100%|██████████| 4/4 [00:00<00:00, 27.17 batches/s, loss=1.808/3.183, train accuracy=100.000/53.278, learning_rate=1.000e-04]\n","Training Epoch 406/1000: 100%|██████████| 4/4 [00:00<00:00, 25.29 batches/s, loss=1.803/3.221, train accuracy=100.000/50.725, learning_rate=1.000e-04]\n","Training Epoch 407/1000: 100%|██████████| 4/4 [00:00<00:00, 21.28 batches/s, loss=1.765/3.170, train accuracy=100.000/52.312, learning_rate=1.000e-04]\n","Training Epoch 408/1000: 100%|██████████| 4/4 [00:00<00:00, 25.83 batches/s, loss=1.729/3.188, train accuracy=100.000/51.829, learning_rate=1.000e-04]\n","Training Epoch 409/1000: 100%|██████████| 4/4 [00:00<00:00, 26.45 batches/s, loss=1.718/3.147, train accuracy=100.000/53.002, learning_rate=1.000e-04]\n","Training Epoch 410/1000: 100%|██████████| 4/4 [00:00<00:00, 24.38 batches/s, loss=1.779/3.154, train accuracy=100.000/53.140, learning_rate=1.000e-04]\n","Training Epoch 411/1000: 100%|██████████| 4/4 [00:00<00:00, 26.57 batches/s, loss=1.767/3.161, train accuracy=100.000/53.071, learning_rate=1.000e-04]\n","Training Epoch 412/1000: 100%|██████████| 4/4 [00:00<00:00, 26.71 batches/s, loss=1.887/3.171, train accuracy=100.000/53.761, learning_rate=1.000e-04]\n","Training Epoch 413/1000: 100%|██████████| 4/4 [00:00<00:00, 21.05 batches/s, loss=1.935/3.187, train accuracy=100.000/52.864, learning_rate=1.000e-04]\n","Training Epoch 414/1000: 100%|██████████| 4/4 [00:00<00:00, 25.14 batches/s, loss=1.811/3.165, train accuracy=100.000/53.347, learning_rate=1.000e-04]\n","Training Epoch 415/1000: 100%|██████████| 4/4 [00:00<00:00, 26.44 batches/s, loss=1.772/3.159, train accuracy=100.000/52.174, learning_rate=1.000e-04]\n","Training Epoch 416/1000: 100%|██████████| 4/4 [00:00<00:00, 24.92 batches/s, loss=1.732/3.127, train accuracy=100.000/52.036, learning_rate=1.000e-04]\n","Training Epoch 417/1000: 100%|██████████| 4/4 [00:00<00:00, 24.90 batches/s, loss=1.712/3.099, train accuracy=100.000/53.968, learning_rate=1.000e-04]\n","Training Epoch 418/1000: 100%|██████████| 4/4 [00:00<00:00, 25.76 batches/s, loss=1.783/3.109, train accuracy=100.000/53.347, learning_rate=1.000e-04]\n","Training Epoch 419/1000: 100%|██████████| 4/4 [00:00<00:00, 20.69 batches/s, loss=1.804/3.135, train accuracy=100.000/53.209, learning_rate=1.000e-04]\n","Training Epoch 420/1000: 100%|██████████| 4/4 [00:00<00:00, 26.11 batches/s, loss=1.761/3.103, train accuracy=100.000/55.072, learning_rate=1.000e-04]\n","Training Epoch 421/1000: 100%|██████████| 4/4 [00:00<00:00, 26.44 batches/s, loss=1.739/3.103, train accuracy=100.000/53.623, learning_rate=1.000e-04]\n","Training Epoch 422/1000: 100%|██████████| 4/4 [00:00<00:00, 23.10 batches/s, loss=1.798/3.080, train accuracy=100.000/55.280, learning_rate=1.000e-04]\n","Training Epoch 423/1000: 100%|██████████| 4/4 [00:00<00:00, 18.74 batches/s, loss=1.768/3.061, train accuracy=100.000/54.589, learning_rate=1.000e-04]\n","Training Epoch 424/1000: 100%|██████████| 4/4 [00:00<00:00, 17.61 batches/s, loss=1.724/3.040, train accuracy=100.000/55.901, learning_rate=1.000e-04]\n","Training Epoch 425/1000: 100%|██████████| 4/4 [00:00<00:00, 16.21 batches/s, loss=1.716/3.042, train accuracy=100.000/54.313, learning_rate=1.000e-04]\n","Training Epoch 426/1000: 100%|██████████| 4/4 [00:00<00:00, 17.86 batches/s, loss=1.735/3.037, train accuracy=100.000/54.037, learning_rate=1.000e-04]\n","Training Epoch 427/1000: 100%|██████████| 4/4 [00:00<00:00, 18.49 batches/s, loss=1.712/3.031, train accuracy=100.000/55.901, learning_rate=1.000e-04]\n","Training Epoch 428/1000: 100%|██████████| 4/4 [00:00<00:00, 16.55 batches/s, loss=1.730/3.015, train accuracy=100.000/57.143, learning_rate=1.000e-04]\n","Training Epoch 429/1000: 100%|██████████| 4/4 [00:00<00:00, 17.90 batches/s, loss=1.743/3.006, train accuracy=100.000/54.589, learning_rate=1.000e-04]\n","Training Epoch 430/1000: 100%|██████████| 4/4 [00:00<00:00, 18.87 batches/s, loss=1.765/3.009, train accuracy=100.000/55.072, learning_rate=1.000e-04]\n","Training Epoch 431/1000: 100%|██████████| 4/4 [00:00<00:00, 16.51 batches/s, loss=1.749/3.008, train accuracy=100.000/54.727, learning_rate=1.000e-04]\n","Training Epoch 432/1000: 100%|██████████| 4/4 [00:00<00:00, 19.97 batches/s, loss=1.766/3.003, train accuracy=100.000/57.350, learning_rate=1.000e-04]\n","Training Epoch 433/1000: 100%|██████████| 4/4 [00:00<00:00, 17.51 batches/s, loss=1.732/2.978, train accuracy=100.000/54.934, learning_rate=1.000e-04]\n","Training Epoch 434/1000: 100%|██████████| 4/4 [00:00<00:00, 16.77 batches/s, loss=1.695/2.954, train accuracy=100.000/56.729, learning_rate=1.000e-04]\n","Training Epoch 435/1000: 100%|██████████| 4/4 [00:00<00:00, 17.63 batches/s, loss=1.721/2.949, train accuracy=100.000/57.764, learning_rate=1.000e-04]\n","Training Epoch 436/1000: 100%|██████████| 4/4 [00:00<00:00, 18.32 batches/s, loss=1.725/2.951, train accuracy=100.000/57.074, learning_rate=1.000e-04]\n","Training Epoch 437/1000: 100%|██████████| 4/4 [00:00<00:00, 16.30 batches/s, loss=1.729/2.926, train accuracy=100.000/57.971, learning_rate=1.000e-04]\n","Training Epoch 438/1000: 100%|██████████| 4/4 [00:00<00:00, 17.68 batches/s, loss=1.723/2.933, train accuracy=100.000/57.419, learning_rate=1.000e-04]\n","Training Epoch 439/1000: 100%|██████████| 4/4 [00:00<00:00, 17.77 batches/s, loss=1.741/2.929, train accuracy=100.000/57.833, learning_rate=1.000e-04]\n","Training Epoch 440/1000: 100%|██████████| 4/4 [00:00<00:00, 17.72 batches/s, loss=1.692/2.894, train accuracy=100.000/58.454, learning_rate=1.000e-04]\n","Training Epoch 441/1000: 100%|██████████| 4/4 [00:00<00:00, 15.65 batches/s, loss=1.730/2.934, train accuracy=100.000/56.591, learning_rate=1.000e-04]\n","Training Epoch 442/1000: 100%|██████████| 4/4 [00:00<00:00, 19.06 batches/s, loss=1.699/2.956, train accuracy=100.000/56.936, learning_rate=1.000e-04]\n","Training Epoch 443/1000: 100%|██████████| 4/4 [00:00<00:00, 25.47 batches/s, loss=1.732/2.938, train accuracy=100.000/58.385, learning_rate=1.000e-04]\n","Training Epoch 444/1000: 100%|██████████| 4/4 [00:00<00:00, 25.89 batches/s, loss=1.748/2.895, train accuracy=100.000/59.213, learning_rate=1.000e-04]\n","Training Epoch 445/1000: 100%|██████████| 4/4 [00:00<00:00, 23.98 batches/s, loss=1.768/2.918, train accuracy=100.000/56.867, learning_rate=1.000e-04]\n","Training Epoch 446/1000: 100%|██████████| 4/4 [00:00<00:00, 21.19 batches/s, loss=1.829/2.910, train accuracy=100.000/57.764, learning_rate=1.000e-04]\n","Training Epoch 447/1000: 100%|██████████| 4/4 [00:00<00:00, 26.13 batches/s, loss=1.745/2.897, train accuracy=100.000/58.178, learning_rate=1.000e-04]\n","Training Epoch 448/1000: 100%|██████████| 4/4 [00:00<00:00, 25.26 batches/s, loss=1.730/2.879, train accuracy=100.000/58.385, learning_rate=1.000e-04]\n","Training Epoch 449/1000: 100%|██████████| 4/4 [00:00<00:00, 26.39 batches/s, loss=1.715/2.885, train accuracy=100.000/58.247, learning_rate=1.000e-04]\n","Training Epoch 450/1000: 100%|██████████| 4/4 [00:00<00:00, 15.72 batches/s, loss=1.706/2.849, train accuracy=100.000/60.524, learning_rate=1.000e-04]\n","Training Epoch 451/1000: 100%|██████████| 4/4 [00:00<00:00,  9.19 batches/s, loss=1.673/2.823, train accuracy=100.000/59.006, learning_rate=1.000e-04]\n","Training Epoch 452/1000: 100%|██████████| 4/4 [00:00<00:00, 17.00 batches/s, loss=1.726/2.831, train accuracy=100.000/59.834, learning_rate=1.000e-04]\n","Training Epoch 453/1000: 100%|██████████| 4/4 [00:00<00:00, 26.18 batches/s, loss=1.757/2.879, train accuracy=100.000/58.661, learning_rate=1.000e-04]\n","Training Epoch 454/1000: 100%|██████████| 4/4 [00:00<00:00, 24.30 batches/s, loss=1.669/2.815, train accuracy=100.000/59.696, learning_rate=1.000e-04]\n","Training Epoch 455/1000: 100%|██████████| 4/4 [00:00<00:00, 14.46 batches/s, loss=1.669/2.800, train accuracy=100.000/59.834, learning_rate=1.000e-04]\n","Training Epoch 456/1000: 100%|██████████| 4/4 [00:00<00:00,  9.56 batches/s, loss=1.717/2.791, train accuracy=100.000/61.905, learning_rate=1.000e-04]\n","Training Epoch 457/1000: 100%|██████████| 4/4 [00:00<00:00, 20.67 batches/s, loss=1.711/2.810, train accuracy=100.000/61.215, learning_rate=1.000e-04]\n","Training Epoch 458/1000: 100%|██████████| 4/4 [00:00<00:00, 21.10 batches/s, loss=1.842/2.839, train accuracy=100.000/60.939, learning_rate=1.000e-04]\n","Training Epoch 459/1000: 100%|██████████| 4/4 [00:00<00:00, 25.53 batches/s, loss=1.760/2.810, train accuracy=100.000/60.386, learning_rate=1.000e-04]\n","Training Epoch 460/1000: 100%|██████████| 4/4 [00:00<00:00, 26.11 batches/s, loss=1.730/2.769, train accuracy=100.000/61.836, learning_rate=1.000e-04]\n","Training Epoch 461/1000: 100%|██████████| 4/4 [00:00<00:00, 25.86 batches/s, loss=1.653/2.752, train accuracy=100.000/62.319, learning_rate=1.000e-04]\n","Training Epoch 462/1000: 100%|██████████| 4/4 [00:00<00:00, 25.91 batches/s, loss=1.670/2.772, train accuracy=100.000/61.698, learning_rate=1.000e-04]\n","Training Epoch 463/1000: 100%|██████████| 4/4 [00:00<00:00, 25.14 batches/s, loss=1.805/2.796, train accuracy=100.000/61.560, learning_rate=1.000e-04]\n","Training Epoch 464/1000: 100%|██████████| 4/4 [00:00<00:00, 20.77 batches/s, loss=1.675/2.732, train accuracy=100.000/62.871, learning_rate=1.000e-04]\n","Training Epoch 465/1000: 100%|██████████| 4/4 [00:00<00:00, 22.77 batches/s, loss=1.704/2.761, train accuracy=100.000/61.767, learning_rate=1.000e-04]\n","Training Epoch 466/1000: 100%|██████████| 4/4 [00:00<00:00, 26.76 batches/s, loss=1.655/2.790, train accuracy=100.000/61.077, learning_rate=1.000e-04]\n","Training Epoch 467/1000: 100%|██████████| 4/4 [00:00<00:00, 25.92 batches/s, loss=1.656/2.732, train accuracy=100.000/61.836, learning_rate=1.000e-04]\n","Training Epoch 468/1000: 100%|██████████| 4/4 [00:00<00:00, 26.30 batches/s, loss=1.755/2.775, train accuracy=100.000/61.077, learning_rate=1.000e-04]\n","Training Epoch 469/1000: 100%|██████████| 4/4 [00:00<00:00, 24.86 batches/s, loss=1.688/2.708, train accuracy=100.000/63.906, learning_rate=1.000e-04]\n","Training Epoch 470/1000: 100%|██████████| 4/4 [00:00<00:00, 19.30 batches/s, loss=1.676/2.734, train accuracy=100.000/62.802, learning_rate=1.000e-04]\n","Training Epoch 471/1000: 100%|██████████| 4/4 [00:00<00:00, 24.96 batches/s, loss=1.689/2.736, train accuracy=100.000/61.905, learning_rate=1.000e-04]\n","Training Epoch 472/1000: 100%|██████████| 4/4 [00:00<00:00, 25.66 batches/s, loss=1.666/2.704, train accuracy=100.000/62.112, learning_rate=1.000e-04]\n","Training Epoch 473/1000: 100%|██████████| 4/4 [00:00<00:00, 25.48 batches/s, loss=1.667/2.695, train accuracy=100.000/62.940, learning_rate=1.000e-04]\n","Training Epoch 474/1000: 100%|██████████| 4/4 [00:00<00:00, 22.57 batches/s, loss=1.683/2.710, train accuracy=100.000/62.733, learning_rate=1.000e-04]\n","Training Epoch 475/1000: 100%|██████████| 4/4 [00:00<00:00, 24.15 batches/s, loss=1.796/2.710, train accuracy=100.000/64.734, learning_rate=1.000e-04]\n","Training Epoch 476/1000: 100%|██████████| 4/4 [00:00<00:00, 18.64 batches/s, loss=1.773/2.709, train accuracy=100.000/63.837, learning_rate=1.000e-04]\n","Training Epoch 477/1000: 100%|██████████| 4/4 [00:00<00:00, 24.93 batches/s, loss=1.700/2.699, train accuracy=100.000/63.699, learning_rate=1.000e-04]\n","Training Epoch 478/1000: 100%|██████████| 4/4 [00:00<00:00, 25.42 batches/s, loss=1.678/2.680, train accuracy=100.000/64.113, learning_rate=1.000e-04]\n","Training Epoch 479/1000: 100%|██████████| 4/4 [00:00<00:00, 24.06 batches/s, loss=1.644/2.663, train accuracy=100.000/64.182, learning_rate=1.000e-04]\n","Training Epoch 480/1000: 100%|██████████| 4/4 [00:00<00:00, 25.60 batches/s, loss=1.696/2.677, train accuracy=100.000/64.044, learning_rate=1.000e-04]\n","Training Epoch 481/1000: 100%|██████████| 4/4 [00:00<00:00, 19.68 batches/s, loss=1.700/2.667, train accuracy=100.000/65.355, learning_rate=1.000e-04]\n","Training Epoch 482/1000: 100%|██████████| 4/4 [00:00<00:00, 23.75 batches/s, loss=1.704/2.664, train accuracy=100.000/64.251, learning_rate=1.000e-04]\n","Training Epoch 483/1000: 100%|██████████| 4/4 [00:00<00:00, 25.76 batches/s, loss=1.676/2.640, train accuracy=100.000/66.115, learning_rate=1.000e-04]\n","Training Epoch 484/1000: 100%|██████████| 4/4 [00:00<00:00, 25.23 batches/s, loss=1.702/2.633, train accuracy=100.000/66.460, learning_rate=1.000e-04]\n","Training Epoch 485/1000: 100%|██████████| 4/4 [00:00<00:00, 26.25 batches/s, loss=1.649/2.626, train accuracy=100.000/65.286, learning_rate=1.000e-04]\n","Training Epoch 486/1000: 100%|██████████| 4/4 [00:00<00:00, 25.33 batches/s, loss=1.696/2.609, train accuracy=100.000/66.598, learning_rate=1.000e-04]\n","Training Epoch 487/1000: 100%|██████████| 4/4 [00:00<00:00, 20.00 batches/s, loss=1.676/2.612, train accuracy=100.000/66.736, learning_rate=1.000e-04]\n","Training Epoch 488/1000: 100%|██████████| 4/4 [00:00<00:00, 24.36 batches/s, loss=1.673/2.597, train accuracy=100.000/65.424, learning_rate=1.000e-04]\n","Training Epoch 489/1000: 100%|██████████| 4/4 [00:00<00:00, 25.15 batches/s, loss=1.746/2.639, train accuracy=100.000/66.115, learning_rate=1.000e-04]\n","Training Epoch 490/1000: 100%|██████████| 4/4 [00:00<00:00, 25.80 batches/s, loss=1.693/2.599, train accuracy=100.000/67.150, learning_rate=1.000e-04]\n","Training Epoch 491/1000: 100%|██████████| 4/4 [00:00<00:00, 25.21 batches/s, loss=1.660/2.606, train accuracy=100.000/65.977, learning_rate=1.000e-04]\n","Training Epoch 492/1000: 100%|██████████| 4/4 [00:00<00:00, 24.12 batches/s, loss=1.664/2.580, train accuracy=100.000/66.874, learning_rate=1.000e-04]\n","Training Epoch 493/1000: 100%|██████████| 4/4 [00:00<00:00, 21.32 batches/s, loss=1.674/2.578, train accuracy=100.000/68.323, learning_rate=1.000e-04]\n","Training Epoch 494/1000: 100%|██████████| 4/4 [00:00<00:00, 20.45 batches/s, loss=1.701/2.566, train accuracy=100.000/67.012, learning_rate=1.000e-04]\n","Training Epoch 495/1000: 100%|██████████| 4/4 [00:00<00:00, 17.72 batches/s, loss=1.687/2.574, train accuracy=100.000/67.219, learning_rate=1.000e-04]\n","Training Epoch 496/1000: 100%|██████████| 4/4 [00:00<00:00, 19.39 batches/s, loss=1.659/2.559, train accuracy=100.000/68.116, learning_rate=1.000e-04]\n","Training Epoch 497/1000: 100%|██████████| 4/4 [00:00<00:00, 14.92 batches/s, loss=1.682/2.565, train accuracy=100.000/67.150, learning_rate=1.000e-04]\n","Training Epoch 498/1000: 100%|██████████| 4/4 [00:00<00:00, 16.30 batches/s, loss=1.667/2.556, train accuracy=100.000/68.323, learning_rate=1.000e-04]\n","Training Epoch 499/1000: 100%|██████████| 4/4 [00:00<00:00, 20.45 batches/s, loss=1.646/2.534, train accuracy=100.000/68.737, learning_rate=1.000e-04]\n","Training Epoch 500/1000: 100%|██████████| 4/4 [00:00<00:00, 16.52 batches/s, loss=1.649/2.527, train accuracy=100.000/67.909, learning_rate=1.000e-04]\n","Training Epoch 501/1000: 100%|██████████| 4/4 [00:00<00:00, 17.56 batches/s, loss=1.656/2.536, train accuracy=100.000/67.771, learning_rate=1.000e-04]\n","Training Epoch 502/1000: 100%|██████████| 4/4 [00:00<00:00, 22.23 batches/s, loss=1.849/2.569, train accuracy=100.000/68.668, learning_rate=1.000e-04]\n","Training Epoch 503/1000: 100%|██████████| 4/4 [00:00<00:00, 15.88 batches/s, loss=1.695/2.554, train accuracy=100.000/68.668, learning_rate=1.000e-04]\n","Training Epoch 504/1000: 100%|██████████| 4/4 [00:00<00:00, 18.22 batches/s, loss=1.730/2.551, train accuracy=100.000/69.496, learning_rate=1.000e-04]\n","Training Epoch 505/1000: 100%|██████████| 4/4 [00:00<00:00, 17.02 batches/s, loss=1.671/2.517, train accuracy=100.000/69.634, learning_rate=1.000e-04]\n","Training Epoch 506/1000: 100%|██████████| 4/4 [00:00<00:00, 15.65 batches/s, loss=1.648/2.518, train accuracy=100.000/69.565, learning_rate=1.000e-04]\n","Training Epoch 507/1000: 100%|██████████| 4/4 [00:00<00:00, 16.98 batches/s, loss=1.691/2.540, train accuracy=100.000/68.737, learning_rate=1.000e-04]\n","Training Epoch 508/1000: 100%|██████████| 4/4 [00:00<00:00, 18.25 batches/s, loss=1.688/2.515, train accuracy=100.000/69.082, learning_rate=1.000e-04]\n","Training Epoch 509/1000: 100%|██████████| 4/4 [00:00<00:00, 17.46 batches/s, loss=1.736/2.524, train accuracy=100.000/69.496, learning_rate=1.000e-04]\n","Training Epoch 510/1000: 100%|██████████| 4/4 [00:00<00:00, 18.45 batches/s, loss=1.687/2.499, train accuracy=100.000/69.634, learning_rate=1.000e-04]\n","Training Epoch 511/1000: 100%|██████████| 4/4 [00:00<00:00, 15.78 batches/s, loss=1.659/2.489, train accuracy=100.000/70.186, learning_rate=1.000e-04]\n","Training Epoch 512/1000: 100%|██████████| 4/4 [00:00<00:00, 16.06 batches/s, loss=1.657/2.467, train accuracy=100.000/71.014, learning_rate=1.000e-04]\n","Training Epoch 513/1000: 100%|██████████| 4/4 [00:00<00:00, 18.01 batches/s, loss=1.657/2.485, train accuracy=100.000/70.945, learning_rate=1.000e-04]\n","Training Epoch 514/1000: 100%|██████████| 4/4 [00:00<00:00, 18.33 batches/s, loss=1.640/2.467, train accuracy=100.000/69.013, learning_rate=1.000e-04]\n","Training Epoch 515/1000: 100%|██████████| 4/4 [00:00<00:00, 25.76 batches/s, loss=1.668/2.464, train accuracy=100.000/70.117, learning_rate=1.000e-04]\n","Training Epoch 516/1000: 100%|██████████| 4/4 [00:00<00:00, 23.45 batches/s, loss=1.637/2.460, train accuracy=100.000/70.531, learning_rate=1.000e-04]\n","Training Epoch 517/1000: 100%|██████████| 4/4 [00:00<00:00, 25.69 batches/s, loss=1.651/2.461, train accuracy=100.000/71.498, learning_rate=1.000e-04]\n","Training Epoch 518/1000: 100%|██████████| 4/4 [00:00<00:00, 25.73 batches/s, loss=1.685/2.458, train accuracy=100.000/71.084, learning_rate=1.000e-04]\n","Training Epoch 519/1000: 100%|██████████| 4/4 [00:00<00:00, 21.21 batches/s, loss=1.830/2.494, train accuracy=100.000/71.636, learning_rate=1.000e-04]\n","Training Epoch 520/1000: 100%|██████████| 4/4 [00:00<00:00, 23.52 batches/s, loss=1.699/2.464, train accuracy=100.000/72.050, learning_rate=1.000e-04]\n","Training Epoch 521/1000: 100%|██████████| 4/4 [00:00<00:00, 24.08 batches/s, loss=1.703/2.482, train accuracy=100.000/70.531, learning_rate=1.000e-04]\n","Training Epoch 522/1000: 100%|██████████| 4/4 [00:00<00:00, 23.38 batches/s, loss=1.649/2.439, train accuracy=100.000/71.014, learning_rate=1.000e-04]\n","Training Epoch 523/1000: 100%|██████████| 4/4 [00:00<00:00, 26.04 batches/s, loss=1.669/2.457, train accuracy=100.000/70.255, learning_rate=1.000e-04]\n","Training Epoch 524/1000: 100%|██████████| 4/4 [00:00<00:00, 25.64 batches/s, loss=1.670/2.422, train accuracy=100.000/73.568, learning_rate=1.000e-04]\n","Training Epoch 525/1000: 100%|██████████| 4/4 [00:00<00:00, 20.19 batches/s, loss=1.632/2.424, train accuracy=100.000/70.945, learning_rate=1.000e-04]\n","Training Epoch 526/1000: 100%|██████████| 4/4 [00:00<00:00, 22.34 batches/s, loss=1.623/2.414, train accuracy=100.000/71.636, learning_rate=1.000e-04]\n","Training Epoch 527/1000: 100%|██████████| 4/4 [00:00<00:00, 25.50 batches/s, loss=1.632/2.400, train accuracy=100.000/73.016, learning_rate=1.000e-04]\n","Training Epoch 528/1000: 100%|██████████| 4/4 [00:00<00:00, 23.79 batches/s, loss=1.676/2.399, train accuracy=100.000/73.982, learning_rate=1.000e-04]\n","Training Epoch 529/1000: 100%|██████████| 4/4 [00:00<00:00, 24.67 batches/s, loss=1.691/2.401, train accuracy=100.000/73.982, learning_rate=1.000e-04]\n","Training Epoch 530/1000: 100%|██████████| 4/4 [00:00<00:00, 23.42 batches/s, loss=1.694/2.415, train accuracy=100.000/72.671, learning_rate=1.000e-04]\n","Training Epoch 531/1000: 100%|██████████| 4/4 [00:00<00:00, 22.07 batches/s, loss=1.687/2.404, train accuracy=100.000/73.913, learning_rate=1.000e-04]\n","Training Epoch 532/1000: 100%|██████████| 4/4 [00:00<00:00, 23.84 batches/s, loss=1.657/2.403, train accuracy=100.000/73.085, learning_rate=1.000e-04]\n","Training Epoch 533/1000: 100%|██████████| 4/4 [00:00<00:00, 24.87 batches/s, loss=1.602/2.362, train accuracy=100.000/73.568, learning_rate=1.000e-04]\n","Training Epoch 534/1000: 100%|██████████| 4/4 [00:00<00:00, 23.66 batches/s, loss=1.616/2.377, train accuracy=100.000/73.154, learning_rate=1.000e-04]\n","Training Epoch 535/1000: 100%|██████████| 4/4 [00:00<00:00, 25.64 batches/s, loss=1.659/2.356, train accuracy=100.000/74.603, learning_rate=1.000e-04]\n","Training Epoch 536/1000: 100%|██████████| 4/4 [00:00<00:00, 20.12 batches/s, loss=1.668/2.375, train accuracy=100.000/73.361, learning_rate=1.000e-04]\n","Training Epoch 537/1000: 100%|██████████| 4/4 [00:00<00:00, 23.09 batches/s, loss=1.660/2.358, train accuracy=100.000/74.051, learning_rate=1.000e-04]\n","Training Epoch 538/1000: 100%|██████████| 4/4 [00:00<00:00, 24.43 batches/s, loss=1.647/2.341, train accuracy=100.000/75.431, learning_rate=1.000e-04]\n","Training Epoch 539/1000: 100%|██████████| 4/4 [00:00<00:00, 22.74 batches/s, loss=1.640/2.354, train accuracy=100.000/74.120, learning_rate=1.000e-04]\n","Training Epoch 540/1000: 100%|██████████| 4/4 [00:00<00:00, 25.70 batches/s, loss=1.626/2.341, train accuracy=100.000/75.707, learning_rate=1.000e-04]\n","Training Epoch 541/1000: 100%|██████████| 4/4 [00:00<00:00, 23.40 batches/s, loss=1.665/2.363, train accuracy=100.000/75.500, learning_rate=1.000e-04]\n","Training Epoch 542/1000: 100%|██████████| 4/4 [00:00<00:00, 20.80 batches/s, loss=1.636/2.367, train accuracy=100.000/73.775, learning_rate=1.000e-04]\n","Training Epoch 543/1000: 100%|██████████| 4/4 [00:00<00:00, 26.14 batches/s, loss=1.671/2.352, train accuracy=100.000/74.741, learning_rate=1.000e-04]\n","Training Epoch 544/1000: 100%|██████████| 4/4 [00:00<00:00, 25.80 batches/s, loss=1.630/2.320, train accuracy=100.000/76.052, learning_rate=1.000e-04]\n","Training Epoch 545/1000: 100%|██████████| 4/4 [00:00<00:00, 25.32 batches/s, loss=1.607/2.307, train accuracy=100.000/75.776, learning_rate=1.000e-04]\n","Training Epoch 546/1000: 100%|██████████| 4/4 [00:00<00:00, 24.23 batches/s, loss=1.684/2.345, train accuracy=100.000/75.776, learning_rate=1.000e-04]\n","Training Epoch 547/1000: 100%|██████████| 4/4 [00:00<00:00, 23.34 batches/s, loss=1.622/2.339, train accuracy=100.000/75.569, learning_rate=1.000e-04]\n","Training Epoch 548/1000: 100%|██████████| 4/4 [00:00<00:00, 20.88 batches/s, loss=1.620/2.320, train accuracy=100.000/76.674, learning_rate=1.000e-04]\n","Training Epoch 549/1000: 100%|██████████| 4/4 [00:00<00:00, 23.86 batches/s, loss=1.666/2.325, train accuracy=100.000/76.259, learning_rate=1.000e-04]\n","Training Epoch 550/1000: 100%|██████████| 4/4 [00:00<00:00, 23.95 batches/s, loss=1.641/2.321, train accuracy=100.000/76.121, learning_rate=1.000e-04]\n","Training Epoch 551/1000: 100%|██████████| 4/4 [00:00<00:00, 23.60 batches/s, loss=1.648/2.293, train accuracy=100.000/76.881, learning_rate=1.000e-04]\n","Training Epoch 552/1000: 100%|██████████| 4/4 [00:00<00:00, 24.42 batches/s, loss=1.774/2.349, train accuracy=100.000/76.121, learning_rate=1.000e-04]\n","Training Epoch 553/1000: 100%|██████████| 4/4 [00:00<00:00, 20.90 batches/s, loss=1.658/2.309, train accuracy=100.000/77.433, learning_rate=1.000e-04]\n","Training Epoch 554/1000: 100%|██████████| 4/4 [00:00<00:00, 23.84 batches/s, loss=1.666/2.306, train accuracy=100.000/76.881, learning_rate=1.000e-04]\n","Training Epoch 555/1000: 100%|██████████| 4/4 [00:00<00:00, 25.09 batches/s, loss=1.702/2.317, train accuracy=100.000/75.983, learning_rate=1.000e-04]\n","Training Epoch 556/1000: 100%|██████████| 4/4 [00:00<00:00, 25.68 batches/s, loss=1.654/2.285, train accuracy=100.000/76.467, learning_rate=1.000e-04]\n","Training Epoch 557/1000: 100%|██████████| 4/4 [00:00<00:00, 22.42 batches/s, loss=1.656/2.276, train accuracy=100.000/77.571, learning_rate=1.000e-04]\n","Training Epoch 558/1000: 100%|██████████| 4/4 [00:00<00:00, 24.61 batches/s, loss=1.634/2.284, train accuracy=100.000/76.674, learning_rate=1.000e-04]\n","Training Epoch 559/1000: 100%|██████████| 4/4 [00:00<00:00, 20.12 batches/s, loss=1.608/2.274, train accuracy=100.000/76.743, learning_rate=1.000e-04]\n","Training Epoch 560/1000: 100%|██████████| 4/4 [00:00<00:00, 24.66 batches/s, loss=1.611/2.281, train accuracy=100.000/77.433, learning_rate=1.000e-04]\n","Training Epoch 561/1000: 100%|██████████| 4/4 [00:00<00:00, 24.97 batches/s, loss=1.629/2.276, train accuracy=100.000/77.571, learning_rate=1.000e-04]\n","Training Epoch 562/1000: 100%|██████████| 4/4 [00:00<00:00, 24.53 batches/s, loss=1.689/2.297, train accuracy=92.857/76.950, learning_rate=1.000e-04]\n","Training Epoch 563/1000: 100%|██████████| 4/4 [00:00<00:00, 23.34 batches/s, loss=1.640/2.270, train accuracy=100.000/78.951, learning_rate=1.000e-04]\n","Training Epoch 564/1000: 100%|██████████| 4/4 [00:00<00:00, 20.68 batches/s, loss=1.635/2.258, train accuracy=100.000/79.020, learning_rate=1.000e-04]\n","Training Epoch 565/1000: 100%|██████████| 4/4 [00:00<00:00, 24.17 batches/s, loss=1.622/2.252, train accuracy=100.000/78.675, learning_rate=1.000e-04]\n","Training Epoch 566/1000: 100%|██████████| 4/4 [00:00<00:00, 24.93 batches/s, loss=1.620/2.238, train accuracy=100.000/79.158, learning_rate=1.000e-04]\n","Training Epoch 567/1000: 100%|██████████| 4/4 [00:00<00:00, 25.52 batches/s, loss=1.644/2.265, train accuracy=100.000/77.571, learning_rate=1.000e-04]\n","Training Epoch 568/1000: 100%|██████████| 4/4 [00:00<00:00, 25.12 batches/s, loss=1.628/2.251, train accuracy=100.000/77.916, learning_rate=1.000e-04]\n","Training Epoch 569/1000: 100%|██████████| 4/4 [00:00<00:00, 23.44 batches/s, loss=1.640/2.248, train accuracy=100.000/79.158, learning_rate=1.000e-04]\n","Training Epoch 570/1000: 100%|██████████| 4/4 [00:00<00:00, 18.88 batches/s, loss=1.607/2.213, train accuracy=100.000/80.814, learning_rate=1.000e-04]\n","Training Epoch 571/1000: 100%|██████████| 4/4 [00:00<00:00, 17.16 batches/s, loss=1.620/2.254, train accuracy=100.000/78.054, learning_rate=1.000e-04]\n","Training Epoch 572/1000: 100%|██████████| 4/4 [00:00<00:00, 18.28 batches/s, loss=1.712/2.235, train accuracy=100.000/80.193, learning_rate=1.000e-04]\n","Training Epoch 573/1000: 100%|██████████| 4/4 [00:00<00:00, 18.68 batches/s, loss=1.654/2.242, train accuracy=100.000/79.917, learning_rate=1.000e-04]\n","Training Epoch 574/1000: 100%|██████████| 4/4 [00:00<00:00, 15.06 batches/s, loss=1.669/2.222, train accuracy=100.000/78.813, learning_rate=1.000e-04]\n","Training Epoch 575/1000: 100%|██████████| 4/4 [00:00<00:00, 16.62 batches/s, loss=1.642/2.210, train accuracy=100.000/79.779, learning_rate=1.000e-04]\n","Training Epoch 576/1000: 100%|██████████| 4/4 [00:00<00:00, 21.19 batches/s, loss=1.648/2.243, train accuracy=100.000/78.054, learning_rate=1.000e-04]\n","Training Epoch 577/1000: 100%|██████████| 4/4 [00:00<00:00, 22.01 batches/s, loss=1.674/2.222, train accuracy=100.000/80.607, learning_rate=1.000e-04]\n","Training Epoch 578/1000: 100%|██████████| 4/4 [00:00<00:00, 15.37 batches/s, loss=1.647/2.236, train accuracy=100.000/79.986, learning_rate=1.000e-04]\n","Training Epoch 579/1000: 100%|██████████| 4/4 [00:00<00:00, 19.01 batches/s, loss=1.582/2.194, train accuracy=100.000/80.883, learning_rate=1.000e-04]\n","Training Epoch 580/1000: 100%|██████████| 4/4 [00:00<00:00, 16.86 batches/s, loss=1.631/2.197, train accuracy=100.000/80.124, learning_rate=1.000e-04]\n","Training Epoch 581/1000: 100%|██████████| 4/4 [00:00<00:00, 19.14 batches/s, loss=1.661/2.221, train accuracy=100.000/79.365, learning_rate=1.000e-04]\n","Training Epoch 582/1000: 100%|██████████| 4/4 [00:00<00:00, 14.80 batches/s, loss=1.633/2.202, train accuracy=100.000/80.469, learning_rate=1.000e-04]\n","Training Epoch 583/1000: 100%|██████████| 4/4 [00:00<00:00, 16.80 batches/s, loss=1.584/2.200, train accuracy=100.000/79.986, learning_rate=1.000e-04]\n","Training Epoch 584/1000: 100%|██████████| 4/4 [00:00<00:00, 15.67 batches/s, loss=1.628/2.185, train accuracy=100.000/80.193, learning_rate=1.000e-04]\n","Training Epoch 585/1000: 100%|██████████| 4/4 [00:00<00:00, 17.12 batches/s, loss=1.625/2.169, train accuracy=100.000/81.435, learning_rate=1.000e-04]\n","Training Epoch 586/1000: 100%|██████████| 4/4 [00:00<00:00, 19.86 batches/s, loss=1.609/2.197, train accuracy=100.000/80.883, learning_rate=1.000e-04]\n","Training Epoch 587/1000: 100%|██████████| 4/4 [00:00<00:00, 16.25 batches/s, loss=1.628/2.177, train accuracy=100.000/80.952, learning_rate=1.000e-04]\n","Training Epoch 588/1000: 100%|██████████| 4/4 [00:00<00:00, 16.82 batches/s, loss=1.644/2.185, train accuracy=100.000/79.917, learning_rate=1.000e-04]\n","Training Epoch 589/1000: 100%|██████████| 4/4 [00:00<00:00, 19.71 batches/s, loss=1.621/2.170, train accuracy=100.000/82.264, learning_rate=1.000e-04]\n","Training Epoch 590/1000: 100%|██████████| 4/4 [00:00<00:00, 16.22 batches/s, loss=1.619/2.171, train accuracy=100.000/81.366, learning_rate=1.000e-04]\n","Training Epoch 591/1000: 100%|██████████| 4/4 [00:00<00:00, 15.36 batches/s, loss=1.591/2.146, train accuracy=100.000/82.540, learning_rate=1.000e-04]\n","Training Epoch 592/1000: 100%|██████████| 4/4 [00:00<00:00, 17.09 batches/s, loss=1.595/2.137, train accuracy=100.000/81.919, learning_rate=1.000e-04]\n","Training Epoch 593/1000: 100%|██████████| 4/4 [00:00<00:00, 19.80 batches/s, loss=1.621/2.136, train accuracy=100.000/83.092, learning_rate=1.000e-04]\n","Training Epoch 594/1000: 100%|██████████| 4/4 [00:00<00:00, 23.88 batches/s, loss=1.604/2.149, train accuracy=100.000/82.885, learning_rate=1.000e-04]\n","Training Epoch 595/1000: 100%|██████████| 4/4 [00:00<00:00, 22.19 batches/s, loss=1.599/2.154, train accuracy=100.000/82.678, learning_rate=1.000e-04]\n","Training Epoch 596/1000: 100%|██████████| 4/4 [00:00<00:00, 20.11 batches/s, loss=1.629/2.153, train accuracy=100.000/82.954, learning_rate=1.000e-04]\n","Training Epoch 597/1000: 100%|██████████| 4/4 [00:00<00:00, 24.26 batches/s, loss=1.628/2.157, train accuracy=100.000/82.747, learning_rate=1.000e-04]\n","Training Epoch 598/1000: 100%|██████████| 4/4 [00:00<00:00, 23.64 batches/s, loss=1.642/2.150, train accuracy=100.000/83.920, learning_rate=1.000e-04]\n","Training Epoch 599/1000: 100%|██████████| 4/4 [00:00<00:00, 24.63 batches/s, loss=1.600/2.127, train accuracy=100.000/83.368, learning_rate=1.000e-04]\n","Training Epoch 600/1000: 100%|██████████| 4/4 [00:00<00:00, 24.92 batches/s, loss=1.680/2.145, train accuracy=100.000/83.299, learning_rate=1.000e-04]\n","Training Epoch 601/1000: 100%|██████████| 4/4 [00:00<00:00, 19.87 batches/s, loss=1.646/2.160, train accuracy=100.000/82.402, learning_rate=1.000e-04]\n","Training Epoch 602/1000: 100%|██████████| 4/4 [00:00<00:00, 23.69 batches/s, loss=1.609/2.154, train accuracy=100.000/82.195, learning_rate=1.000e-04]\n","Training Epoch 603/1000: 100%|██████████| 4/4 [00:00<00:00, 23.67 batches/s, loss=1.669/2.154, train accuracy=100.000/82.885, learning_rate=1.000e-04]\n","Training Epoch 604/1000: 100%|██████████| 4/4 [00:00<00:00, 24.02 batches/s, loss=1.622/2.130, train accuracy=100.000/83.023, learning_rate=1.000e-04]\n","Training Epoch 605/1000: 100%|██████████| 4/4 [00:00<00:00, 25.31 batches/s, loss=1.635/2.138, train accuracy=100.000/83.368, learning_rate=1.000e-04]\n","Training Epoch 606/1000: 100%|██████████| 4/4 [00:00<00:00, 22.71 batches/s, loss=1.644/2.131, train accuracy=100.000/83.437, learning_rate=1.000e-04]\n","Training Epoch 607/1000: 100%|██████████| 4/4 [00:00<00:00, 20.76 batches/s, loss=1.598/2.141, train accuracy=100.000/82.678, learning_rate=1.000e-04]\n","Training Epoch 608/1000: 100%|██████████| 4/4 [00:00<00:00,  7.88 batches/s, loss=1.616/2.115, train accuracy=100.000/82.885, learning_rate=1.000e-04]\n","Training Epoch 609/1000: 100%|██████████| 4/4 [00:00<00:00, 14.81 batches/s, loss=1.571/2.118, train accuracy=100.000/83.920, learning_rate=1.000e-04]\n","Training Epoch 610/1000: 100%|██████████| 4/4 [00:00<00:00, 24.10 batches/s, loss=1.674/2.135, train accuracy=100.000/83.782, learning_rate=1.000e-04]\n","Training Epoch 611/1000: 100%|██████████| 4/4 [00:00<00:00, 22.16 batches/s, loss=1.621/2.113, train accuracy=100.000/83.851, learning_rate=1.000e-04]\n","Training Epoch 612/1000: 100%|██████████| 4/4 [00:00<00:00, 24.83 batches/s, loss=1.621/2.112, train accuracy=100.000/83.851, learning_rate=1.000e-04]\n","Training Epoch 613/1000: 100%|██████████| 4/4 [00:00<00:00, 23.71 batches/s, loss=1.591/2.091, train accuracy=100.000/84.541, learning_rate=1.000e-04]\n","Training Epoch 614/1000: 100%|██████████| 4/4 [00:00<00:00, 24.33 batches/s, loss=1.570/2.100, train accuracy=100.000/83.989, learning_rate=1.000e-04]\n","Training Epoch 615/1000: 100%|██████████| 4/4 [00:00<00:00, 20.82 batches/s, loss=1.576/2.120, train accuracy=100.000/83.161, learning_rate=1.000e-04]\n","Training Epoch 616/1000: 100%|██████████| 4/4 [00:00<00:00, 20.45 batches/s, loss=1.573/2.082, train accuracy=100.000/85.162, learning_rate=1.000e-04]\n","Training Epoch 617/1000: 100%|██████████| 4/4 [00:00<00:00, 24.69 batches/s, loss=1.646/2.115, train accuracy=100.000/83.782, learning_rate=1.000e-04]\n","Training Epoch 618/1000: 100%|██████████| 4/4 [00:00<00:00, 23.61 batches/s, loss=1.607/2.084, train accuracy=100.000/84.817, learning_rate=1.000e-04]\n","Training Epoch 619/1000: 100%|██████████| 4/4 [00:00<00:00, 24.68 batches/s, loss=1.662/2.126, train accuracy=100.000/83.644, learning_rate=1.000e-04]\n","Training Epoch 620/1000: 100%|██████████| 4/4 [00:00<00:00, 22.03 batches/s, loss=1.625/2.087, train accuracy=100.000/85.714, learning_rate=1.000e-04]\n","Training Epoch 621/1000: 100%|██████████| 4/4 [00:00<00:00, 21.81 batches/s, loss=1.616/2.088, train accuracy=100.000/84.265, learning_rate=1.000e-04]\n","Training Epoch 622/1000: 100%|██████████| 4/4 [00:00<00:00, 21.37 batches/s, loss=1.610/2.085, train accuracy=100.000/83.920, learning_rate=1.000e-04]\n","Training Epoch 623/1000: 100%|██████████| 4/4 [00:00<00:00, 24.25 batches/s, loss=1.577/2.070, train accuracy=100.000/84.265, learning_rate=1.000e-04]\n","Training Epoch 624/1000: 100%|██████████| 4/4 [00:00<00:00, 24.78 batches/s, loss=1.578/2.079, train accuracy=100.000/84.265, learning_rate=1.000e-04]\n","Training Epoch 625/1000: 100%|██████████| 4/4 [00:00<00:00, 24.66 batches/s, loss=1.618/2.098, train accuracy=100.000/84.472, learning_rate=1.000e-04]\n","Training Epoch 626/1000: 100%|██████████| 4/4 [00:00<00:00, 20.16 batches/s, loss=1.561/2.059, train accuracy=100.000/85.231, learning_rate=1.000e-04]\n","Training Epoch 627/1000: 100%|██████████| 4/4 [00:00<00:00, 23.98 batches/s, loss=1.587/2.055, train accuracy=100.000/85.645, learning_rate=1.000e-04]\n","Training Epoch 628/1000: 100%|██████████| 4/4 [00:00<00:00, 22.70 batches/s, loss=1.650/2.075, train accuracy=100.000/85.300, learning_rate=1.000e-04]\n","Training Epoch 629/1000: 100%|██████████| 4/4 [00:00<00:00, 23.51 batches/s, loss=1.620/2.068, train accuracy=100.000/86.128, learning_rate=1.000e-04]\n","Training Epoch 630/1000: 100%|██████████| 4/4 [00:00<00:00, 22.80 batches/s, loss=1.619/2.072, train accuracy=100.000/86.335, learning_rate=1.000e-04]\n","Training Epoch 631/1000: 100%|██████████| 4/4 [00:00<00:00, 21.51 batches/s, loss=1.590/2.056, train accuracy=100.000/86.059, learning_rate=1.000e-04]\n","Training Epoch 632/1000: 100%|██████████| 4/4 [00:00<00:00, 22.36 batches/s, loss=1.592/2.073, train accuracy=100.000/84.748, learning_rate=1.000e-04]\n","Training Epoch 633/1000: 100%|██████████| 4/4 [00:00<00:00, 22.75 batches/s, loss=1.654/2.066, train accuracy=100.000/85.507, learning_rate=1.000e-04]\n","Training Epoch 634/1000: 100%|██████████| 4/4 [00:00<00:00, 24.14 batches/s, loss=1.626/2.058, train accuracy=100.000/86.266, learning_rate=1.000e-04]\n","Training Epoch 635/1000: 100%|██████████| 4/4 [00:00<00:00, 24.09 batches/s, loss=1.644/2.066, train accuracy=100.000/86.957, learning_rate=1.000e-04]\n","Training Epoch 636/1000: 100%|██████████| 4/4 [00:00<00:00, 24.37 batches/s, loss=1.621/2.072, train accuracy=100.000/84.817, learning_rate=1.000e-04]\n","Training Epoch 637/1000: 100%|██████████| 4/4 [00:00<00:00, 18.95 batches/s, loss=1.608/2.087, train accuracy=100.000/84.334, learning_rate=1.000e-04]\n","Training Epoch 638/1000: 100%|██████████| 4/4 [00:00<00:00, 24.62 batches/s, loss=1.636/2.057, train accuracy=100.000/87.095, learning_rate=1.000e-04]\n","Training Epoch 639/1000: 100%|██████████| 4/4 [00:00<00:00, 21.77 batches/s, loss=1.577/2.031, train accuracy=100.000/86.335, learning_rate=1.000e-04]\n","Training Epoch 640/1000: 100%|██████████| 4/4 [00:00<00:00, 24.35 batches/s, loss=1.595/2.047, train accuracy=100.000/86.197, learning_rate=1.000e-04]\n","Training Epoch 641/1000: 100%|██████████| 4/4 [00:00<00:00, 24.47 batches/s, loss=1.618/2.057, train accuracy=100.000/86.957, learning_rate=1.000e-04]\n","Training Epoch 642/1000: 100%|██████████| 4/4 [00:00<00:00, 20.83 batches/s, loss=1.580/2.045, train accuracy=100.000/85.783, learning_rate=1.000e-04]\n","Training Epoch 643/1000: 100%|██████████| 4/4 [00:00<00:00, 22.98 batches/s, loss=1.566/2.031, train accuracy=100.000/87.233, learning_rate=1.000e-04]\n","Training Epoch 644/1000: 100%|██████████| 4/4 [00:00<00:00, 24.17 batches/s, loss=1.611/2.044, train accuracy=100.000/85.438, learning_rate=1.000e-04]\n","Training Epoch 645/1000: 100%|██████████| 4/4 [00:00<00:00, 20.69 batches/s, loss=1.586/2.049, train accuracy=100.000/86.335, learning_rate=1.000e-04]\n","Training Epoch 646/1000: 100%|██████████| 4/4 [00:00<00:00, 18.79 batches/s, loss=1.606/2.035, train accuracy=100.000/87.716, learning_rate=1.000e-04]\n","Training Epoch 647/1000: 100%|██████████| 4/4 [00:00<00:00, 16.17 batches/s, loss=1.564/2.028, train accuracy=100.000/86.680, learning_rate=1.000e-04]\n","Training Epoch 648/1000: 100%|██████████| 4/4 [00:00<00:00, 17.81 batches/s, loss=1.623/2.051, train accuracy=100.000/86.818, learning_rate=1.000e-04]\n","Training Epoch 649/1000: 100%|██████████| 4/4 [00:00<00:00, 17.34 batches/s, loss=1.581/2.016, train accuracy=100.000/86.266, learning_rate=1.000e-04]\n","Training Epoch 650/1000: 100%|██████████| 4/4 [00:00<00:00, 17.11 batches/s, loss=1.631/2.035, train accuracy=100.000/86.888, learning_rate=1.000e-04]\n","Training Epoch 651/1000: 100%|██████████| 4/4 [00:00<00:00, 14.76 batches/s, loss=1.551/2.002, train accuracy=100.000/87.647, learning_rate=1.000e-04]\n","Training Epoch 652/1000: 100%|██████████| 4/4 [00:00<00:00, 18.21 batches/s, loss=1.643/2.046, train accuracy=100.000/87.233, learning_rate=1.000e-04]\n","Training Epoch 653/1000: 100%|██████████| 4/4 [00:00<00:00, 15.07 batches/s, loss=1.620/2.021, train accuracy=100.000/87.095, learning_rate=1.000e-04]\n","Training Epoch 654/1000: 100%|██████████| 4/4 [00:00<00:00, 16.12 batches/s, loss=1.591/2.019, train accuracy=100.000/87.647, learning_rate=1.000e-04]\n","Training Epoch 655/1000: 100%|██████████| 4/4 [00:00<00:00, 15.39 batches/s, loss=1.624/2.004, train accuracy=100.000/87.992, learning_rate=1.000e-04]\n","Training Epoch 656/1000: 100%|██████████| 4/4 [00:00<00:00, 18.53 batches/s, loss=1.576/2.000, train accuracy=100.000/88.199, learning_rate=1.000e-04]\n","Training Epoch 657/1000: 100%|██████████| 4/4 [00:00<00:00, 15.02 batches/s, loss=1.553/2.003, train accuracy=100.000/88.544, learning_rate=1.000e-04]\n","Training Epoch 658/1000: 100%|██████████| 4/4 [00:00<00:00, 15.17 batches/s, loss=1.550/1.983, train accuracy=100.000/87.716, learning_rate=1.000e-04]\n","Training Epoch 659/1000: 100%|██████████| 4/4 [00:00<00:00, 13.83 batches/s, loss=1.657/2.010, train accuracy=100.000/88.337, learning_rate=1.000e-04]\n","Training Epoch 660/1000: 100%|██████████| 4/4 [00:00<00:00, 15.81 batches/s, loss=1.611/1.997, train accuracy=100.000/87.992, learning_rate=1.000e-04]\n","Training Epoch 661/1000: 100%|██████████| 4/4 [00:00<00:00, 16.34 batches/s, loss=1.582/2.015, train accuracy=100.000/88.061, learning_rate=1.000e-04]\n","Training Epoch 662/1000: 100%|██████████| 4/4 [00:00<00:00, 14.20 batches/s, loss=1.568/2.006, train accuracy=100.000/87.026, learning_rate=1.000e-04]\n","Training Epoch 663/1000: 100%|██████████| 4/4 [00:00<00:00, 14.60 batches/s, loss=1.596/1.983, train accuracy=100.000/89.855, learning_rate=1.000e-04]\n","Training Epoch 664/1000: 100%|██████████| 4/4 [00:00<00:00, 14.19 batches/s, loss=1.573/1.985, train accuracy=100.000/87.992, learning_rate=1.000e-04]\n","Training Epoch 665/1000: 100%|██████████| 4/4 [00:00<00:00, 20.71 batches/s, loss=1.565/1.974, train accuracy=100.000/89.165, learning_rate=1.000e-04]\n","Training Epoch 666/1000: 100%|██████████| 4/4 [00:00<00:00, 20.85 batches/s, loss=1.577/1.986, train accuracy=100.000/89.510, learning_rate=1.000e-04]\n","Training Epoch 667/1000: 100%|██████████| 4/4 [00:00<00:00, 22.51 batches/s, loss=1.580/1.988, train accuracy=100.000/89.441, learning_rate=1.000e-04]\n","Training Epoch 668/1000: 100%|██████████| 4/4 [00:00<00:00, 24.22 batches/s, loss=1.558/1.983, train accuracy=100.000/87.992, learning_rate=1.000e-04]\n","Training Epoch 669/1000: 100%|██████████| 4/4 [00:00<00:00, 23.75 batches/s, loss=1.539/1.961, train accuracy=100.000/89.165, learning_rate=1.000e-04]\n","Training Epoch 670/1000: 100%|██████████| 4/4 [00:00<00:00, 24.11 batches/s, loss=1.562/1.970, train accuracy=100.000/89.786, learning_rate=1.000e-04]\n","Training Epoch 671/1000: 100%|██████████| 4/4 [00:00<00:00, 22.10 batches/s, loss=1.574/1.981, train accuracy=100.000/87.785, learning_rate=1.000e-04]\n","Training Epoch 672/1000: 100%|██████████| 4/4 [00:00<00:00, 19.77 batches/s, loss=1.596/2.000, train accuracy=100.000/87.371, learning_rate=1.000e-04]\n","Training Epoch 673/1000: 100%|██████████| 4/4 [00:00<00:00, 22.96 batches/s, loss=1.596/1.969, train accuracy=100.000/89.165, learning_rate=1.000e-04]\n","Training Epoch 674/1000: 100%|██████████| 4/4 [00:00<00:00, 24.64 batches/s, loss=1.566/1.962, train accuracy=100.000/90.269, learning_rate=1.000e-04]\n","Training Epoch 675/1000: 100%|██████████| 4/4 [00:00<00:00, 23.70 batches/s, loss=1.576/1.969, train accuracy=100.000/88.337, learning_rate=1.000e-04]\n","Training Epoch 676/1000: 100%|██████████| 4/4 [00:00<00:00, 23.45 batches/s, loss=1.567/1.978, train accuracy=100.000/88.820, learning_rate=1.000e-04]\n","Training Epoch 677/1000: 100%|██████████| 4/4 [00:00<00:00, 19.02 batches/s, loss=1.573/1.966, train accuracy=100.000/89.372, learning_rate=1.000e-04]\n","Training Epoch 678/1000: 100%|██████████| 4/4 [00:00<00:00, 21.30 batches/s, loss=1.561/1.948, train accuracy=100.000/89.993, learning_rate=1.000e-04]\n","Training Epoch 679/1000: 100%|██████████| 4/4 [00:00<00:00, 25.18 batches/s, loss=1.673/1.990, train accuracy=100.000/89.165, learning_rate=1.000e-04]\n","Training Epoch 680/1000: 100%|██████████| 4/4 [00:00<00:00, 24.02 batches/s, loss=1.634/1.986, train accuracy=100.000/89.855, learning_rate=1.000e-04]\n","Training Epoch 681/1000: 100%|██████████| 4/4 [00:00<00:00, 24.61 batches/s, loss=1.586/1.976, train accuracy=100.000/89.303, learning_rate=1.000e-04]\n","Training Epoch 682/1000: 100%|██████████| 4/4 [00:00<00:00, 22.64 batches/s, loss=1.579/1.969, train accuracy=100.000/88.682, learning_rate=1.000e-04]\n","Training Epoch 683/1000: 100%|██████████| 4/4 [00:00<00:00, 20.31 batches/s, loss=1.554/1.962, train accuracy=100.000/89.096, learning_rate=1.000e-04]\n","Training Epoch 684/1000: 100%|██████████| 4/4 [00:00<00:00, 24.70 batches/s, loss=1.591/1.972, train accuracy=100.000/88.751, learning_rate=1.000e-04]\n","Training Epoch 685/1000: 100%|██████████| 4/4 [00:00<00:00, 23.96 batches/s, loss=1.556/1.947, train accuracy=100.000/90.200, learning_rate=1.000e-04]\n","Training Epoch 686/1000: 100%|██████████| 4/4 [00:00<00:00, 25.36 batches/s, loss=1.608/1.954, train accuracy=100.000/90.062, learning_rate=1.000e-04]\n","Training Epoch 687/1000: 100%|██████████| 4/4 [00:00<00:00, 24.37 batches/s, loss=1.585/1.954, train accuracy=100.000/89.165, learning_rate=1.000e-04]\n","Training Epoch 688/1000: 100%|██████████| 4/4 [00:00<00:00, 20.90 batches/s, loss=1.573/1.961, train accuracy=100.000/89.303, learning_rate=1.000e-04]\n","Training Epoch 689/1000: 100%|██████████| 4/4 [00:00<00:00, 22.73 batches/s, loss=1.557/1.943, train accuracy=100.000/90.683, learning_rate=1.000e-04]\n","Training Epoch 690/1000: 100%|██████████| 4/4 [00:00<00:00, 25.30 batches/s, loss=1.556/1.941, train accuracy=100.000/90.407, learning_rate=1.000e-04]\n","Training Epoch 691/1000: 100%|██████████| 4/4 [00:00<00:00, 25.19 batches/s, loss=1.581/1.952, train accuracy=100.000/89.372, learning_rate=1.000e-04]\n","Training Epoch 692/1000: 100%|██████████| 4/4 [00:00<00:00, 13.19 batches/s, loss=1.577/1.947, train accuracy=100.000/90.683, learning_rate=1.000e-04]\n","Training Epoch 693/1000: 100%|██████████| 4/4 [00:00<00:00,  8.18 batches/s, loss=1.545/1.929, train accuracy=100.000/90.407, learning_rate=1.000e-04]\n","Training Epoch 694/1000: 100%|██████████| 4/4 [00:00<00:00, 24.10 batches/s, loss=1.555/1.944, train accuracy=100.000/89.924, learning_rate=1.000e-04]\n","Training Epoch 695/1000: 100%|██████████| 4/4 [00:00<00:00, 26.00 batches/s, loss=1.622/1.951, train accuracy=100.000/89.993, learning_rate=1.000e-04]\n","Training Epoch 696/1000: 100%|██████████| 4/4 [00:00<00:00, 24.59 batches/s, loss=1.569/1.942, train accuracy=100.000/90.821, learning_rate=1.000e-04]\n","Training Epoch 697/1000: 100%|██████████| 4/4 [00:00<00:00, 19.90 batches/s, loss=1.579/1.946, train accuracy=100.000/90.545, learning_rate=1.000e-04]\n","Training Epoch 698/1000: 100%|██████████| 4/4 [00:00<00:00, 23.53 batches/s, loss=1.584/1.943, train accuracy=100.000/89.234, learning_rate=1.000e-04]\n","Training Epoch 699/1000: 100%|██████████| 4/4 [00:00<00:00, 24.43 batches/s, loss=1.610/1.957, train accuracy=100.000/89.027, learning_rate=1.000e-04]\n","Training Epoch 700/1000: 100%|██████████| 4/4 [00:00<00:00, 25.61 batches/s, loss=1.570/1.929, train accuracy=100.000/90.683, learning_rate=1.000e-04]\n","Training Epoch 701/1000: 100%|██████████| 4/4 [00:00<00:00, 24.53 batches/s, loss=1.570/1.930, train accuracy=100.000/91.511, learning_rate=1.000e-04]\n","Training Epoch 702/1000: 100%|██████████| 4/4 [00:00<00:00, 23.75 batches/s, loss=1.560/1.916, train accuracy=100.000/91.304, learning_rate=1.000e-04]\n","Training Epoch 703/1000: 100%|██████████| 4/4 [00:00<00:00, 18.94 batches/s, loss=1.514/1.903, train accuracy=100.000/91.235, learning_rate=1.000e-04]\n","Training Epoch 704/1000: 100%|██████████| 4/4 [00:00<00:00, 25.72 batches/s, loss=1.566/1.907, train accuracy=100.000/91.718, learning_rate=1.000e-04]\n","Training Epoch 705/1000: 100%|██████████| 4/4 [00:00<00:00, 24.50 batches/s, loss=1.564/1.923, train accuracy=100.000/91.166, learning_rate=1.000e-04]\n","Training Epoch 706/1000: 100%|██████████| 4/4 [00:00<00:00, 24.43 batches/s, loss=1.542/1.921, train accuracy=100.000/90.890, learning_rate=1.000e-04]\n","Training Epoch 707/1000: 100%|██████████| 4/4 [00:00<00:00, 25.21 batches/s, loss=1.541/1.919, train accuracy=100.000/90.752, learning_rate=1.000e-04]\n","Training Epoch 708/1000: 100%|██████████| 4/4 [00:00<00:00, 21.68 batches/s, loss=1.549/1.916, train accuracy=100.000/90.683, learning_rate=1.000e-04]\n","Training Epoch 709/1000:  25%|██▌       | 1/4 [00:00<00:00, 12.72 batches/s, loss=2.070/2.070, train accuracy=87.680/87.680, learning_rate=1.000e-04]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-74-3435b262f1ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/drive/MyDrive/exercise_11/exercise_code/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, reset_epoch)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_loader\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/exercise_11/exercise_code/trainer.py\u001b[0m in \u001b[0;36m_train_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m                     \u001b[0mstart_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/exercise_11/exercise_code/trainer.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, batch, metrics)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mlabel_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_length'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;31m########################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/exercise_11/exercise_code/network/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, encoder_inputs, decoder_inputs, encoder_mask, decoder_mask)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mencoder_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mencoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0mdecoder_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mdecoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/exercise_11/exercise_code/network/encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, encoder_mask)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# Loop through the encoder blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/exercise_11/exercise_code/network/encoder_block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, pad_mask)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_mask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/exercise_11/exercise_code/network/multi_head_attention.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, q, k, v, mask)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;31m# Final linear projection and dropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1694\u001b[0m     \u001b[0;31m# See full discussion on the problems with returning `Union` here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1695\u001b[0m     \u001b[0;31m# https://github.com/microsoft/pyright/issues/4213\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1696\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1697\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_parameters'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1698\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":76,"id":"b34fcc24c4a3ee07","metadata":{"executionInfo":{"elapsed":508,"status":"ok","timestamp":1720358639475,"user":{"displayName":"Hoàng Lê","userId":"12538776912584899644"},"user_tz":-120},"id":"b34fcc24c4a3ee07"},"outputs":[],"source":["def translate(input_sentence, max_iteration_length = 50, probabilistic = False, returns_scores = False):\n","    # Tokenize input sentence\n","    encoder_input = torch.tensor(tokenizer.encode(input_sentence))\n","\n","    # Retrieve output sequence from model\n","    output_sequence, score_records = model.predict(encoder_input, max_iteration_length, probabilistic, returns_scores)\n","\n","    # Decode output sequence\n","    output_sequence = tokenizer.decode(output_sequence, skip_special_tokens=True)\n","\n","    if returns_scores:\n","        return output_sequence, score_records\n","    return output_sequence"]},{"cell_type":"code","execution_count":78,"id":"11848183f60a3b90","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3219,"status":"ok","timestamp":1720358647670,"user":{"displayName":"Hoàng Lê","userId":"12538776912584899644"},"user_tz":-120},"id":"11848183f60a3b90","outputId":"787ef7d9-1f47-46ec-b972-ed4f35266771"},"outputs":[{"name":"stdout","output_type":"stream","text":["Hallo, wie geht es dir heute?\n"]}],"source":["output_sequence = translate(\"Hi, how are you today?\", probabilistic=False)\n","print(output_sequence)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"}},"nbformat":4,"nbformat_minor":5}
